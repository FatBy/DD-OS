#!/usr/bin/env python3
"""
DD-OS Native Server v3.0
ç‹¬ç«‹è¿è¡Œçš„æœ¬åœ° AI æ“ä½œç³»ç»Ÿåç«¯

åŠŸèƒ½:
    - æ–‡ä»¶æ“ä½œ (è¯»/å†™/åˆ—ç›®å½•)
    - å‘½ä»¤æ‰§è¡Œ (Shell)
    - ä»»åŠ¡ç®¡ç† (åå°æ‰§è¡Œ)
    - è®°å¿†æŒä¹…åŒ–

ç”¨æ³•:
    python ddos-local-server.py [--port 3001] [--path ~/clawd]

API:
    GET  /status              - æœåŠ¡çŠ¶æ€
    GET  /files               - åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
    GET  /file/<name>         - è·å–æ–‡ä»¶å†…å®¹
    GET  /skills              - è·å–æŠ€èƒ½åˆ—è¡¨
    GET  /memories            - è·å–è®°å¿†æ•°æ®
    GET  /all                 - è·å–æ‰€æœ‰æ•°æ®
    POST /api/tools/execute   - æ‰§è¡Œå·¥å…· (æ–°)
    POST /task/execute        - æ‰§è¡Œä»»åŠ¡ (å…¼å®¹æ—§æ¥å£)
    GET  /task/status/<id>    - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
"""

import os
import sys
import json
import argparse
import threading
import time
import uuid
import subprocess
import shlex
from pathlib import Path
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import unquote, urlparse, parse_qs
from datetime import datetime

VERSION = "4.0.0"

# ğŸ›¡ï¸ å®‰å…¨é…ç½®
DANGEROUS_COMMANDS = {'rm -rf /', 'format', 'mkfs', 'dd if=/dev/zero'}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB æœ€å¤§æ–‡ä»¶å¤§å°
MAX_OUTPUT_SIZE = 512 * 1024      # 512KB æœ€å¤§è¾“å‡º
PLUGIN_TIMEOUT = 60               # æ’ä»¶æ‰§è¡Œè¶…æ—¶(ç§’)


# ============================================
# ğŸ”Œ åŠ¨æ€å·¥å…·æ³¨å†Œè¡¨
# ============================================

class ToolRegistry:
    """åŠ¨æ€å·¥å…·å‘ç°ä¸æ³¨å†Œ - æ”¯æŒå†…ç½®å·¥å…· + æ’ä»¶å·¥å…·"""

    def __init__(self, clawd_path: Path):
        self.clawd_path = clawd_path
        self.builtin_tools: dict = {}      # name -> callable
        self.plugin_tools: dict = {}       # name -> ToolSpec dict

    def register_builtin(self, name: str, handler):
        """æ³¨å†Œå†…ç½®å·¥å…·"""
        self.builtin_tools[name] = handler

    def scan_plugins(self):
        """æ‰«æ skills/ ç›®å½•ï¼Œè‡ªåŠ¨æ³¨å†Œæœ‰ manifest.json çš„æ’ä»¶å·¥å…·"""
        skills_dir = self.clawd_path / 'skills'
        if not skills_dir.exists():
            return

        found = 0
        for item in skills_dir.iterdir():
            if not item.is_dir():
                continue
            manifest_path = item / 'manifest.json'
            if not manifest_path.exists():
                continue
            try:
                spec = json.loads(manifest_path.read_text(encoding='utf-8'))
                
                # æ”¯æŒä¸¤ç§ manifest æ ¼å¼:
                # 1. æ–°æ ¼å¼: { "tools": [{ "toolName": "...", ... }, ...] }
                # 2. æ—§æ ¼å¼: { "toolName": "...", ... }
                
                tools_list = spec.get('tools', [])
                if not tools_list:
                    # æ—§æ ¼å¼: å•ä¸ªå·¥å…·å®šä¹‰
                    tools_list = [spec]
                
                for tool_spec in tools_list:
                    tool_name = tool_spec.get('toolName', '')
                    executable = tool_spec.get('executable', spec.get('executable', 'execute.py'))
                    
                    if not tool_name:
                        continue

                    exe_path = item / executable
                    if not exe_path.exists():
                        print(f"[ToolRegistry] Warning: {exe_path} not found, skipping {tool_name}")
                        continue

                    # å†…ç½®å·¥å…·ä¸å¯è¢«è¦†ç›–
                    if tool_name in self.builtin_tools:
                        print(f"[ToolRegistry] Warning: plugin '{tool_name}' conflicts with builtin, skipping")
                        continue

                    self.plugin_tools[tool_name] = {
                        'name': tool_name,
                        'exe_path': str(exe_path),
                        'runtime': tool_spec.get('runtime', spec.get('runtime', 'python')),
                        'inputs': tool_spec.get('inputs', {}),
                        'outputs': tool_spec.get('outputs', {}),
                        'description': tool_spec.get('description', ''),
                        'dangerLevel': tool_spec.get('dangerLevel', 'safe'),
                        'version': tool_spec.get('version', spec.get('version', '1.0.0')),
                        'skill_dir': str(item),
                        'keywords': tool_spec.get('keywords', []),
                    }
                    found += 1
                    print(f"[ToolRegistry] Registered plugin: {tool_name} ({exe_path.name})")
                    
            except Exception as e:
                print(f"[ToolRegistry] Error loading {manifest_path}: {e}")

        if found > 0:
            print(f"[ToolRegistry] {found} plugin tool(s) registered")

    def is_registered(self, name: str) -> bool:
        return name in self.builtin_tools or name in self.plugin_tools

    def get_plugin(self, name: str) -> dict | None:
        return self.plugin_tools.get(name)

    def list_all(self) -> list:
        """è¿”å›æ‰€æœ‰å·²æ³¨å†Œå·¥å…·ï¼ˆå†…ç½®+æ’ä»¶ï¼‰"""
        tools = []
        for name in self.builtin_tools:
            tools.append({'name': name, 'type': 'builtin'})
        for name, spec in self.plugin_tools.items():
            tools.append({
                'name': name,
                'type': 'plugin',
                'description': spec.get('description', ''),
                'inputs': spec.get('inputs', {}),
                'dangerLevel': spec.get('dangerLevel', 'safe'),
                'version': spec.get('version', '1.0.0'),
            })
        return tools


class ClawdDataHandler(BaseHTTPRequestHandler):
    clawd_path = None
    registry = None  # type: ToolRegistry
    tasks = {}
    tasks_lock = threading.Lock()
    
    def log_message(self, format, *args):
        timestamp = datetime.now().strftime('%H:%M:%S')
        print(f"[{timestamp}] {format % args}")
    
    def send_cors_headers(self):
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
    
    def send_json(self, data, status=200):
        self.send_response(status)
        self.send_header('Content-Type', 'application/json')
        self.send_cors_headers()
        self.end_headers()
        self.wfile.write(json.dumps(data, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def send_text(self, text, status=200):
        self.send_response(status)
        self.send_header('Content-Type', 'text/plain; charset=utf-8')
        self.send_cors_headers()
        self.end_headers()
        self.wfile.write(text.encode('utf-8'))
    
    def send_error_json(self, message, status=404):
        self.send_json({'error': message, 'status': 'error'}, status)
    
    def do_OPTIONS(self):
        self.send_response(200)
        self.send_cors_headers()
        self.end_headers()
    
    def do_GET(self):
        parsed = urlparse(self.path)
        path = unquote(parsed.path)
        query = parse_qs(parsed.query)
        
        routes = {
            '/status': self.handle_status,
            '/files': self.handle_files,
            '/skills': self.handle_skills,
            '/memories': self.handle_memories,
            '/tools': self.handle_tools_list,
            '/all': self.handle_all,
            '/': self.handle_index,
            '': self.handle_index,
        }
        
        if path in routes:
            routes[path]()
        elif path.startswith('/file/'):
            self.handle_file(path[6:])
        elif path.startswith('/task/status/'):
            task_id = path[13:]
            offset = int(query.get('offset', ['0'])[0])
            self.handle_task_status(task_id, offset)
        elif path == '/api/traces/search':
            self.handle_trace_search(query)
        else:
            self.send_error_json(f'Unknown endpoint: {path}', 404)
    
    def do_POST(self):
        parsed = urlparse(self.path)
        path = unquote(parsed.path)
        
        content_length = int(self.headers.get('Content-Length', 0))
        body = self.rfile.read(content_length).decode('utf-8') if content_length > 0 else '{}'
        
        try:
            data = json.loads(body) if body else {}
        except json.JSONDecodeError:
            self.send_error_json('Invalid JSON', 400)
            return
        
        # ğŸŒŸ æ–°å¢ï¼šå·¥å…·æ‰§è¡Œæ¥å£
        if path == '/api/tools/execute':
            self.handle_tool_execution(data)
        elif path == '/tools/reload':
            self.handle_tools_reload(data)
        elif path == '/api/traces/save':
            self.handle_trace_save(data)
        elif path == '/task/execute':
            self.handle_task_execute(data)
        else:
            self.send_error_json(f'Unknown endpoint: {path}', 404)
    
    # ============================================
    # ğŸ› ï¸ å·¥å…·æ‰§è¡Œ (æ ¸å¿ƒæ–°åŠŸèƒ½)
    # ============================================
    
    def handle_tool_execution(self, data):
        """å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚ - æ”¯æŒå†…ç½®å·¥å…·å’Œæ’ä»¶å·¥å…·"""
        tool_name = data.get('name', '')
        args = data.get('args', {})

        if not self.registry.is_registered(tool_name):
            all_tools = [t['name'] for t in self.registry.list_all()]
            self.send_json({
                'tool': tool_name,
                'status': 'error',
                'result': f'Tool not registered: {tool_name}. Available: {", ".join(all_tools)}'
            }, 403)
            return

        result = ""
        status = "success"

        try:
            # ä¼˜å…ˆæ£€æŸ¥æ’ä»¶å·¥å…·
            plugin_spec = self.registry.get_plugin(tool_name)
            if plugin_spec:
                result = self._execute_plugin_tool(plugin_spec, tool_name, args)
            else:
                # å†…ç½®å·¥å…·è°ƒåº¦
                builtin_handlers = {
                    'readFile': self._tool_read_file,
                    'writeFile': self._tool_write_file,
                    'appendFile': self._tool_append_file,
                    'listDir': self._tool_list_dir,
                    'runCmd': self._tool_run_cmd,
                    'weather': self._tool_weather,
                    'webSearch': self._tool_web_search,
                    'saveMemory': self._tool_save_memory,
                    'searchMemory': self._tool_search_memory,
                }
                handler = builtin_handlers.get(tool_name)
                if handler:
                    result = handler(args)
                else:
                    raise ValueError(f"No handler for builtin tool: {tool_name}")

        except Exception as e:
            status = "error"
            result = f"Tool execution failed: {str(e)}"

        self.send_json({
            'tool': tool_name,
            'status': status,
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

    def _execute_plugin_tool(self, spec: dict, tool_name: str, args: dict) -> str:
        """æ‰§è¡Œæ’ä»¶å·¥å…· - subprocess éš”ç¦»æ‰§è¡Œ"""
        exe_path = spec['exe_path']
        runtime = spec.get('runtime', 'python')

        # ç¡®å®šè¿è¡Œæ—¶å‘½ä»¤
        if runtime == 'python':
            cmd = [sys.executable, exe_path]
        elif runtime == 'node':
            cmd = ['node', exe_path]
        else:
            raise ValueError(f"Unsupported runtime: {runtime}")

        # æ„å»ºè¾“å…¥ï¼šåŒ…å«å·¥å…·åå’Œå‚æ•°ï¼ˆæ”¯æŒå¤šå·¥å…· manifestï¼‰
        input_data = json.dumps({
            'tool': tool_name,
            'args': args
        }, ensure_ascii=False)

        try:
            process = subprocess.run(
                cmd,
                input=input_data,
                capture_output=True,
                text=True,
                timeout=PLUGIN_TIMEOUT,
                cwd=spec.get('skill_dir', str(self.clawd_path)),
            )

            if process.returncode != 0:
                stderr = process.stderr[:MAX_OUTPUT_SIZE] if process.stderr else ''
                raise RuntimeError(f"Plugin exited with code {process.returncode}: {stderr}")

            return process.stdout[:MAX_OUTPUT_SIZE] if process.stdout else ''

        except subprocess.TimeoutExpired:
            raise RuntimeError(f"Plugin timed out after {PLUGIN_TIMEOUT}s")
    
    def _resolve_path(self, relative_path: str, allow_outside: bool = False) -> Path:
        """è§£æå¹¶éªŒè¯è·¯å¾„å®‰å…¨æ€§"""
        if not relative_path:
            raise ValueError("Path cannot be empty")
        
        # ç§»é™¤å¼€å¤´çš„æ–œæ 
        clean_path = relative_path.lstrip('/')
        
        # é»˜è®¤åœ¨ clawd ç›®å½•ä¸‹æ“ä½œ
        if allow_outside and os.path.isabs(relative_path):
            file_path = Path(relative_path)
        else:
            file_path = self.clawd_path / clean_path
        
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†
        try:
            resolved = file_path.resolve()
            if not allow_outside:
                resolved.relative_to(self.clawd_path.resolve())
        except ValueError:
            raise PermissionError(f"Access denied: path outside allowed directory")
        
        return resolved
    
    def _tool_read_file(self, args: dict) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        path = args.get('path', '')
        file_path = self._resolve_path(path, allow_outside=args.get('allowOutside', False))
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {path}")
        if not file_path.is_file():
            raise ValueError(f"Not a file: {path}")
        if file_path.stat().st_size > MAX_FILE_SIZE:
            raise ValueError(f"File too large (>{MAX_FILE_SIZE} bytes)")
        
        return file_path.read_text(encoding='utf-8')
    
    def _tool_write_file(self, args: dict) -> str:
        """å†™å…¥æ–‡ä»¶"""
        path = args.get('path', '')
        content = args.get('content', '')
        
        file_path = self._resolve_path(path)
        
        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_path.write_text(content, encoding='utf-8')
        return f"Written {len(content)} bytes to {file_path.name}"
    
    def _tool_append_file(self, args: dict) -> str:
        """è¿½åŠ å†…å®¹åˆ°æ–‡ä»¶"""
        path = args.get('path', '')
        content = args.get('content', '')
        
        file_path = self._resolve_path(path)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(content)
        
        return f"Appended {len(content)} bytes to {file_path.name}"
    
    def _tool_list_dir(self, args: dict) -> str:
        """åˆ—å‡ºç›®å½•å†…å®¹"""
        path = args.get('path', '.')
        dir_path = self._resolve_path(path)
        
        if not dir_path.exists():
            raise FileNotFoundError(f"Directory not found: {path}")
        if not dir_path.is_dir():
            raise ValueError(f"Not a directory: {path}")
        
        items = []
        for item in sorted(dir_path.iterdir()):
            item_type = 'dir' if item.is_dir() else 'file'
            size = item.stat().st_size if item.is_file() else 0
            items.append({
                'name': item.name,
                'type': item_type,
                'size': size
            })
        
        return json.dumps(items, ensure_ascii=False)
    
    def _tool_run_cmd(self, args: dict) -> str:
        """æ‰§è¡Œ Shell å‘½ä»¤ (âš ï¸ é«˜å±æ“ä½œ)"""
        command = args.get('command', '')
        cwd = args.get('cwd', str(self.clawd_path))
        timeout = min(args.get('timeout', 60), 300)  # æœ€å¤§ 5 åˆ†é’Ÿ
        
        if not command:
            raise ValueError("Command cannot be empty")
        
        # å®‰å…¨æ£€æŸ¥
        cmd_lower = command.lower()
        for dangerous in DANGEROUS_COMMANDS:
            if dangerous in cmd_lower:
                raise PermissionError(f"Dangerous command blocked: {command}")
        
        try:
            process = subprocess.run(
                command,
                shell=True,
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            stdout = process.stdout[:MAX_OUTPUT_SIZE] if process.stdout else ''
            stderr = process.stderr[:MAX_OUTPUT_SIZE] if process.stderr else ''
            
            result_parts = []
            if stdout:
                result_parts.append(f"STDOUT:\n{stdout}")
            if stderr:
                result_parts.append(f"STDERR:\n{stderr}")
            result_parts.append(f"Exit Code: {process.returncode}")
            
            return '\n'.join(result_parts)
        
        except subprocess.TimeoutExpired:
            return f"Command timed out after {timeout}s"
    
    def _tool_weather(self, args: dict) -> str:
        """æŸ¥è¯¢å¤©æ°” (åŸºäº OpenClaw weather skill)"""
        import urllib.request
        import urllib.parse
        
        location = args.get('location', args.get('city', ''))
        if not location:
            raise ValueError("Location/city is required")
        
        # ä½¿ç”¨ wttr.in API (æ— éœ€ API Key)
        encoded_location = urllib.parse.quote(location)
        
        try:
            # è·å–è¯¦ç»†å¤©æ°”ä¿¡æ¯
            url = f"https://wttr.in/{encoded_location}?format=j1"
            req = urllib.request.Request(url, headers={'User-Agent': 'curl/7.68.0'})
            
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
            
            current = data.get('current_condition', [{}])[0]
            area = data.get('nearest_area', [{}])[0]
            
            # æ ¼å¼åŒ–è¾“å‡º
            city_name = area.get('areaName', [{}])[0].get('value', location)
            country = area.get('country', [{}])[0].get('value', '')
            
            result = f"""å¤©æ°”æŸ¥è¯¢ç»“æœ - {city_name}, {country}

å½“å‰æ¸©åº¦: {current.get('temp_C', 'N/A')}Â°C (ä½“æ„Ÿ: {current.get('FeelsLikeC', 'N/A')}Â°C)
å¤©æ°”çŠ¶å†µ: {current.get('weatherDesc', [{}])[0].get('value', 'N/A')}
æ¹¿åº¦: {current.get('humidity', 'N/A')}%
é£é€Ÿ: {current.get('windspeedKmph', 'N/A')} km/h ({current.get('winddir16Point', '')})
èƒ½è§åº¦: {current.get('visibility', 'N/A')} km
ç´«å¤–çº¿æŒ‡æ•°: {current.get('uvIndex', 'N/A')}
"""
            return result
            
        except Exception as e:
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•æ ¼å¼
            try:
                simple_url = f"https://wttr.in/{encoded_location}?format=%l:+%c+%t+(%f)+%h+%w"
                req = urllib.request.Request(simple_url, headers={'User-Agent': 'curl/7.68.0'})
                with urllib.request.urlopen(req, timeout=10) as response:
                    return response.read().decode('utf-8')
            except:
                return f"æ— æ³•æŸ¥è¯¢ {location} çš„å¤©æ°”: {str(e)}"
    
    def _tool_web_search(self, args: dict) -> str:
        """ç½‘é¡µæœç´¢ (ä½¿ç”¨ DuckDuckGo HTML)"""
        import urllib.request
        import urllib.parse
        import re
        
        query = args.get('query', args.get('q', ''))
        if not query:
            raise ValueError("Search query is required")
        
        encoded_query = urllib.parse.quote(query)
        
        try:
            # ä½¿ç”¨ DuckDuckGo HTML ç‰ˆæœ¬
            url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
            req = urllib.request.Request(url, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            with urllib.request.urlopen(req, timeout=15) as response:
                html = response.read().decode('utf-8')
            
            # æå–æœç´¢ç»“æœ
            results = []
            # åŒ¹é…ç»“æœé“¾æ¥å’Œæ ‡é¢˜
            pattern = r'<a[^>]+class="result__a"[^>]*href="([^"]*)"[^>]*>([^<]*)</a>'
            matches = re.findall(pattern, html)
            
            for i, (link, title) in enumerate(matches[:5]):  # å–å‰5ä¸ªç»“æœ
                # æ¸…ç† DuckDuckGo é‡å®šå‘é“¾æ¥
                if 'uddg=' in link:
                    actual_link = urllib.parse.unquote(link.split('uddg=')[-1].split('&')[0])
                else:
                    actual_link = link
                results.append(f"{i+1}. {title.strip()}\n   {actual_link}")
            
            if results:
                return f"æœç´¢ '{query}' çš„ç»“æœ:\n\n" + "\n\n".join(results)
            else:
                return f"æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³ç»“æœ"
                
        except Exception as e:
            return f"æœç´¢å¤±è´¥: {str(e)}"
    
    def _tool_save_memory(self, args: dict) -> str:
        """ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶"""
        key = args.get('key', '')
        content = args.get('content', '')
        memory_type = args.get('type', 'general')
        
        if not key or not content:
            raise ValueError("key å’Œ content å‚æ•°å¿…å¡«")
        
        # è®°å¿†å­˜å‚¨åœ¨ memory ç›®å½•ä¸‹
        memory_dir = self.clawd_path / 'memory'
        memory_dir.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰æ—¥æœŸç»„ç»‡è®°å¿†æ–‡ä»¶
        today = datetime.now().strftime('%Y-%m-%d')
        memory_file = memory_dir / f'{today}.md'
        
        # æ ¼å¼åŒ–è®°å¿†æ¡ç›®
        timestamp = datetime.now().strftime('%H:%M:%S')
        entry = f"\n## [{timestamp}] {key}\n- **ç±»å‹**: {memory_type}\n- **å†…å®¹**: {content}\n"
        
        # è¿½åŠ åˆ°è®°å¿†æ–‡ä»¶
        with open(memory_file, 'a', encoding='utf-8') as f:
            f.write(entry)
        
        return f"è®°å¿†å·²ä¿å­˜: {key} (ç±»å‹: {memory_type})"
    
    def _tool_search_memory(self, args: dict) -> str:
        """æ£€ç´¢å†å²è®°å¿†"""
        query = args.get('query', '')
        
        if not query:
            raise ValueError("query å‚æ•°å¿…å¡«")
        
        memory_dir = self.clawd_path / 'memory'
        if not memory_dir.exists():
            return "è®°å¿†åº“ä¸ºç©ºï¼Œæš‚æ— å†å²è®°å¿†ã€‚"
        
        results = []
        query_lower = query.lower()
        
        # éå†æ‰€æœ‰è®°å¿†æ–‡ä»¶
        for memory_file in sorted(memory_dir.glob('*.md'), reverse=True)[:7]:  # æœ€è¿‘7å¤©
            try:
                content = memory_file.read_text(encoding='utf-8')
                
                # æŒ‰æ¡ç›®åˆ†å‰²
                entries = content.split('\n## ')
                for entry in entries:
                    if query_lower in entry.lower():
                        # æå–æ—¥æœŸå’Œå†…å®¹
                        date = memory_file.stem
                        results.append(f"[{date}] {entry.strip()[:200]}")
                        
                        if len(results) >= 5:  # æœ€å¤šè¿”å›5æ¡
                            break
            except Exception:
                continue
            
            if len(results) >= 5:
                break
        
        if results:
            return f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†:\n\n" + "\n\n---\n\n".join(results)
        else:
            return f"æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„è®°å¿†ã€‚"
    
    # ============================================
    # åŸæœ‰å¤„ç†å™¨ (ä¿æŒå…¼å®¹)
    # ============================================
    
    def handle_index(self):
        html = f"""<!DOCTYPE html>
<html>
<head><title>DD-OS Native Server</title></head>
<body style="font-family: monospace; background: #0f172a; color: #e2e8f0; padding: 30px;">
<h1>DD-OS Native Server v{VERSION}</h1>
<p style="color: #94a3b8;">ç‹¬ç«‹è¿è¡Œçš„æœ¬åœ° AI æ“ä½œç³»ç»Ÿåç«¯</p>
<p>Clawd Path: <code style="color: #22d3ee;">{self.clawd_path}</code></p>

<h2>ğŸ“¡ API Endpoints</h2>
<div style="background: #1e293b; padding: 15px; border-radius: 8px;">
<h3 style="color: #f59e0b;">æ•°æ®è¯»å–</h3>
<ul>
<li><a href="/status" style="color: #60a5fa;">/status</a> - æœåŠ¡çŠ¶æ€</li>
<li><a href="/files" style="color: #60a5fa;">/files</a> - æ–‡ä»¶åˆ—è¡¨</li>
<li><a href="/file/SOUL.md" style="color: #60a5fa;">/file/SOUL.md</a> - è¯»å– SOUL</li>
<li><a href="/skills" style="color: #60a5fa;">/skills</a> - æŠ€èƒ½åˆ—è¡¨</li>
<li><a href="/all" style="color: #60a5fa;">/all</a> - æ‰€æœ‰æ•°æ®</li>
</ul>

<h3 style="color: #10b981;">ğŸ› ï¸ å·¥å…·æ‰§è¡Œ (POST)</h3>
<ul>
<li><code>/api/tools/execute</code> - æ‰§è¡Œå·¥å…·</li>
<li>æ”¯æŒ: readFile, writeFile, listDir, runCmd, appendFile</li>
</ul>
</div>

<h2>ğŸ§ª æµ‹è¯•</h2>
<pre style="background: #1e293b; padding: 15px; border-radius: 8px; overflow-x: auto;">
curl -X POST http://localhost:3001/api/tools/execute \\
  -H "Content-Type: application/json" \\
  -d '{{"name": "listDir", "args": {{"path": "."}}}}'
</pre>
</body>
</html>"""
        
        self.send_response(200)
        self.send_header('Content-Type', 'text/html; charset=utf-8')
        self.send_cors_headers()
        self.end_headers()
        self.wfile.write(html.encode('utf-8'))
    
    def handle_status(self):
        files = list_files(self.clawd_path)
        skills_dir = self.clawd_path / 'skills'
        skill_count = len(list(skills_dir.iterdir())) if skills_dir.exists() else 0
        
        self.send_json({
            'status': 'ok',
            'version': VERSION,
            'mode': 'native',
            'clawdPath': str(self.clawd_path),
            'fileCount': len(files),
            'skillCount': skill_count,
            'tools': [t['name'] for t in self.registry.list_all()],
            'toolCount': len(self.registry.list_all()),
            'timestamp': datetime.now().isoformat()
        })
    
    def handle_files(self):
        files = list_files(self.clawd_path)
        self.send_json(files)
    
    def handle_file(self, filename):
        filepath = self.clawd_path / filename
        if not filepath.exists():
            self.send_error_json(f'File not found: {filename}', 404)
            return
        
        if not filepath.is_file():
            self.send_error_json(f'Not a file: {filename}', 400)
            return
        
        try:
            filepath.resolve().relative_to(self.clawd_path.resolve())
        except ValueError:
            self.send_error_json('Access denied', 403)
            return
        
        try:
            content = filepath.read_text(encoding='utf-8')
            self.send_text(content)
        except Exception as e:
            self.send_error_json(f'Read error: {str(e)}', 500)
    
    def handle_skills(self):
        skills = []
        skills_dir = self.clawd_path / 'skills'
        
        if skills_dir.exists() and skills_dir.is_dir():
            for item in skills_dir.iterdir():
                if item.is_dir():
                    skill_md = item / 'SKILL.md'
                    manifest_path = item / 'manifest.json'
                    description = ''
                    skill_data = {
                        'name': item.name,
                        'description': description,
                        'location': 'local',
                        'path': str(item),
                        'status': 'active',
                        'enabled': True,
                    }

                    # è¯»å– SKILL.md æè¿°
                    if skill_md.exists():
                        try:
                            content = skill_md.read_text(encoding='utf-8')
                            for line in content.split('\n'):
                                line = line.strip()
                                if line and not line.startswith('#'):
                                    skill_data['description'] = line[:100]
                                    break
                        except:
                            pass

                    # è¯»å– manifest.json (P1: å¯æ‰§è¡ŒæŠ€èƒ½å…ƒæ•°æ®)
                    if manifest_path.exists():
                        try:
                            manifest = json.loads(manifest_path.read_text(encoding='utf-8'))
                            skill_data['toolName'] = manifest.get('toolName', '')
                            skill_data['executable'] = bool(manifest.get('executable', ''))
                            skill_data['inputs'] = manifest.get('inputs', {})
                            skill_data['dangerLevel'] = manifest.get('dangerLevel', 'safe')
                            skill_data['keywords'] = manifest.get('keywords', [])
                            skill_data['version'] = manifest.get('version', '1.0.0')
                            if manifest.get('description'):
                                skill_data['description'] = manifest['description']
                        except:
                            pass

                    skills.append(skill_data)
        
        self.send_json(skills)

    def handle_tools_list(self):
        """GET /tools - åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·"""
        self.send_json(self.registry.list_all())

    def handle_tools_reload(self, data=None):
        """POST /tools/reload - çƒ­é‡è½½æ’ä»¶å·¥å…·"""
        self.registry.plugin_tools.clear()
        self.registry.scan_plugins()
        tools = self.registry.list_all()
        self.send_json({
            'status': 'ok',
            'message': f'Reloaded. {len(tools)} tools registered.',
            'tools': tools,
        })

    def handle_trace_save(self, data):
        """POST /api/traces/save - ä¿å­˜æ‰§è¡Œè¿½è¸ª (P2: æ‰§è¡Œæµè®°å¿†)"""
        if not data:
            self.send_error_json('Missing trace data', 400)
            return

        traces_dir = self.clawd_path / 'memory' / 'exec_traces'
        traces_dir.mkdir(parents=True, exist_ok=True)

        # æŒ‰æœˆåˆ†ç‰‡å­˜å‚¨
        month = datetime.now().strftime('%Y-%m')
        trace_file = traces_dir / f'{month}.jsonl'

        # æ•æ„Ÿæ•°æ®è„±æ•
        trace_json = json.dumps(data, ensure_ascii=False)
        import re
        trace_json = re.sub(
            r'(password|token|secret|api_key|apikey|auth)["\s:]*["\']([^"\']{3,})["\']',
            r'\1": "***"',
            trace_json,
            flags=re.IGNORECASE
        )

        try:
            with open(trace_file, 'a', encoding='utf-8') as f:
                f.write(trace_json + '\n')

            self.send_json({
                'status': 'ok',
                'message': f'Trace saved to {month}.jsonl',
            })
        except Exception as e:
            self.send_error_json(f'Failed to save trace: {e}', 500)

    def handle_trace_search(self, query_params):
        """GET /api/traces/search?query=xxx&limit=5 - æ£€ç´¢æ‰§è¡Œè¿½è¸ª (P2)"""
        query = query_params.get('query', [''])[0]
        limit = min(int(query_params.get('limit', ['5'])[0]), 20)

        if not query:
            self.send_json([])
            return

        traces_dir = self.clawd_path / 'memory' / 'exec_traces'
        if not traces_dir.exists():
            self.send_json([])
            return

        query_lower = query.lower()
        query_words = [w for w in query_lower.split() if len(w) > 1]
        results = []

        # ä»æœ€è¿‘çš„æœˆä»½æ–‡ä»¶å¼€å§‹æœç´¢
        for trace_file in sorted(traces_dir.glob('*.jsonl'), reverse=True)[:6]:
            try:
                for line in reversed(trace_file.read_text(encoding='utf-8').strip().split('\n')):
                    if not line.strip():
                        continue
                    try:
                        trace = json.loads(line)
                        task = trace.get('task', '').lower()
                        tags = [t.lower() for t in trace.get('tags', [])]
                        # å…³é”®è¯åŒ¹é…: task æè¿°æˆ– tags
                        matched = any(w in task for w in query_words) or \
                                  any(w in ' '.join(tags) for w in query_words)
                        if matched:
                            results.append(trace)
                            if len(results) >= limit:
                                break
                    except json.JSONDecodeError:
                        continue
            except Exception:
                continue
            if len(results) >= limit:
                break

        self.send_json(results)
    
    def handle_memories(self):
        memories = []
        
        memory_md = self.clawd_path / 'MEMORY.md'
        if memory_md.exists():
            try:
                content = memory_md.read_text(encoding='utf-8')
                memories.extend(parse_memory_md(content))
            except:
                pass
        
        memory_dir = self.clawd_path / 'memory'
        if memory_dir.exists() and memory_dir.is_dir():
            for item in memory_dir.iterdir():
                if item.is_file() and item.suffix == '.md':
                    try:
                        content = item.read_text(encoding='utf-8')
                        memories.append({
                            'id': f'file-{item.stem}',
                            'title': item.stem.replace('-', ' ').replace('_', ' ').title(),
                            'content': content[:500],
                            'type': 'long-term',
                            'timestamp': item.stat().st_mtime,
                            'tags': [],
                        })
                    except:
                        pass
        
        self.send_json(memories)
    
    def handle_all(self):
        data = {
            'soul': None,
            'identity': None,
            'skills': [],
            'memories': [],
            'files': list_files(self.clawd_path),
        }
        
        soul_path = self.clawd_path / 'SOUL.md'
        if soul_path.exists():
            try:
                data['soul'] = soul_path.read_text(encoding='utf-8')
            except:
                pass
        
        identity_path = self.clawd_path / 'IDENTITY.md'
        if identity_path.exists():
            try:
                data['identity'] = identity_path.read_text(encoding='utf-8')
            except:
                pass
        
        skills_dir = self.clawd_path / 'skills'
        if skills_dir.exists():
            for item in skills_dir.iterdir():
                if item.is_dir():
                    data['skills'].append({
                        'name': item.name,
                        'location': 'local',
                        'status': 'active',
                        'enabled': True,
                    })
        
        memory_md = self.clawd_path / 'MEMORY.md'
        if memory_md.exists():
            try:
                content = memory_md.read_text(encoding='utf-8')
                data['memories'] = parse_memory_md(content)
            except:
                pass
        
        self.send_json(data)
    
    def handle_task_execute(self, data):
        """å…¼å®¹æ—§çš„ä»»åŠ¡æ‰§è¡Œæ¥å£"""
        prompt = data.get('prompt', '').strip()
        if not prompt:
            self.send_error_json('Missing prompt', 400)
            return
        
        task_id = str(uuid.uuid4())[:8]
        
        thread = threading.Thread(
            target=run_task_in_background,
            args=(task_id, prompt, self.clawd_path),
            daemon=True,
        )
        thread.start()
        
        self.send_json({
            'taskId': task_id,
            'status': 'running',
        })
    
    def handle_task_status(self, task_id, offset=0):
        with self.tasks_lock:
            task = self.tasks.get(task_id)
        
        if not task:
            self.send_error_json(f'Task not found: {task_id}', 404)
            return
        
        log_path = task.get('logPath')
        content = ''
        new_offset = offset
        has_more = False
        file_size = task.get('fileSize', 0)
        
        if log_path:
            content, new_offset, has_more = read_log_chunk(log_path, offset)
            try:
                file_size = Path(log_path).stat().st_size
            except:
                pass
        
        self.send_json({
            'taskId': task_id,
            'status': task['status'],
            'content': content,
            'offset': new_offset,
            'hasMore': has_more,
            'fileSize': file_size,
        })


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def list_files(clawd_path):
    files = []
    try:
        for item in clawd_path.iterdir():
            if item.is_file():
                files.append(item.name)
    except:
        pass
    return sorted(files)


def parse_memory_md(content):
    memories = []
    sections = content.split('## ')
    
    for i, section in enumerate(sections[1:], 1):
        lines = section.strip().split('\n')
        if not lines:
            continue
        
        title = lines[0].strip()
        body = '\n'.join(lines[1:]).strip()
        
        if title:
            memories.append({
                'id': f'memory-{i}',
                'title': title,
                'content': body[:500] if body else title,
                'type': 'long-term',
                'timestamp': None,
                'tags': [],
            })
    
    return memories


def read_log_chunk(log_path, offset=0, max_bytes=51200):
    path = Path(log_path)
    if not path.exists():
        return ('', offset, False)
    
    try:
        file_size = path.stat().st_size
    except:
        return ('', offset, False)
    
    if offset >= file_size:
        return ('', offset, False)
    
    try:
        with open(path, 'rb') as f:
            f.seek(offset)
            raw = f.read(max_bytes)
        
        content = raw.decode('utf-8', errors='replace')
        new_offset = offset + len(raw)
        has_more = new_offset < file_size
        return (content, new_offset, has_more)
    except Exception as e:
        return (f'[æ—¥å¿—è¯»å–é”™è¯¯: {e}]', offset, False)


def run_task_in_background(task_id, prompt, clawd_path):
    logs_dir = clawd_path / 'logs'
    logs_dir.mkdir(exist_ok=True)
    log_file = logs_dir / f"{task_id}.log"
    
    with ClawdDataHandler.tasks_lock:
        ClawdDataHandler.tasks[task_id] = {
            'taskId': task_id,
            'status': 'running',
            'logPath': str(log_file),
            'fileSize': 0,
        }
    
    try:
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"Task: {prompt}\n")
            f.write(f"Started: {datetime.now().isoformat()}\n")
            f.write("-" * 50 + "\n\n")
        
        # å°è¯•è¿è¡Œ clawdbotï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ¨¡æ‹Ÿ
        try:
            with open(log_file, 'ab') as f:
                process = subprocess.Popen(
                    ['clawdbot', 'agent', '--agent', 'main', '--message', prompt],
                    cwd=str(clawd_path),
                    stdout=f,
                    stderr=subprocess.STDOUT,
                )
                
                start_time = time.time()
                timeout = 300
                
                while process.poll() is None:
                    time.sleep(0.5)
                    try:
                        with ClawdDataHandler.tasks_lock:
                            ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
                    except:
                        pass
                    
                    if time.time() - start_time > timeout:
                        process.kill()
                        process.wait()
                        with ClawdDataHandler.tasks_lock:
                            ClawdDataHandler.tasks[task_id]['status'] = 'error'
                            ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
                        with open(log_file, 'a', encoding='utf-8') as ef:
                            ef.write(f'\n\n[é”™è¯¯] ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ ({timeout}s)\n')
                        return
                
                process.wait()
            
            with ClawdDataHandler.tasks_lock:
                ClawdDataHandler.tasks[task_id]['status'] = 'done' if process.returncode == 0 else 'error'
                ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
        
        except FileNotFoundError:
            # clawdbot ä¸å­˜åœ¨ï¼Œä½¿ç”¨ Native æ¨¡å¼æç¤º
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write("\n[DD-OS Native] clawdbot æœªå®‰è£…ã€‚\n")
                f.write("åœ¨ Native æ¨¡å¼ä¸‹ï¼Œè¯·ä½¿ç”¨ /api/tools/execute æ¥å£ç›´æ¥æ‰§è¡Œå·¥å…·ã€‚\n")
                f.write("\nä»»åŠ¡å·²è®°å½•ï¼Œç­‰å¾… AI å¼•æ“å¤„ç†ã€‚\n")
            
            with ClawdDataHandler.tasks_lock:
                ClawdDataHandler.tasks[task_id]['status'] = 'done'
                ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
    
    except Exception as e:
        with open(log_file, 'a', encoding='utf-8') as ef:
            ef.write(f'\n\n[é”™è¯¯] {str(e)}\n')
        with ClawdDataHandler.tasks_lock:
            ClawdDataHandler.tasks[task_id]['status'] = 'error'
            ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size


def cleanup_old_logs(clawd_path, max_age_hours=24):
    logs_dir = clawd_path / 'logs'
    if not logs_dir.exists():
        return
    
    now = time.time()
    count = 0
    for f in logs_dir.glob('*.log'):
        try:
            age = now - f.stat().st_mtime
            if age > max_age_hours * 3600:
                f.unlink()
                count += 1
        except:
            pass
    
    if count > 0:
        print(f"[Cleanup] Removed {count} old log files")


def cleanup_old_traces(clawd_path, max_months=6):
    """æ¸…ç†è¿‡æœŸçš„æ‰§è¡Œè¿½è¸ªæ–‡ä»¶ (P2: ä¿ç•™æœ€è¿‘Nä¸ªæœˆ)"""
    traces_dir = clawd_path / 'memory' / 'exec_traces'
    if not traces_dir.exists():
        return

    files = sorted(traces_dir.glob('*.jsonl'))
    if len(files) <= max_months:
        return

    old_files = files[:-max_months]
    for f in old_files:
        try:
            f.unlink()
            print(f"[Cleanup] Removed old trace: {f.name}")
        except:
            pass


def main():
    parser = argparse.ArgumentParser(description='DD-OS Native Server')
    parser.add_argument('--port', type=int, default=3001, help='Server port (default: 3001)')
    parser.add_argument('--path', type=str, default='~/clawd', help='Data directory path (default: ~/clawd)')
    parser.add_argument('--host', type=str, default='0.0.0.0', help='Server host (default: 0.0.0.0)')
    args = parser.parse_args()
    
    clawd_path = Path(args.path).expanduser().resolve()
    
    if not clawd_path.exists():
        print(f"Creating data directory: {clawd_path}")
        clawd_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºé»˜è®¤ SOUL.md
        soul_file = clawd_path / 'SOUL.md'
        soul_file.write_text("""# DD-OS Native Soul

You are DD-OS, a local AI operating system running directly on the user's computer.

## Core Principles
- Be helpful and efficient
- Protect user data and privacy
- Execute tasks safely
- Learn from interactions

## Available Tools
- readFile: Read file contents
- writeFile: Write file contents
- listDir: List directory contents
- runCmd: Execute shell commands

## Safety Rules
- Never delete system files
- Ask before destructive operations
- Keep execution logs
""", encoding='utf-8')
        print(f"Created default SOUL.md")
    
    logs_dir = clawd_path / 'logs'
    logs_dir.mkdir(exist_ok=True)
    
    memory_dir = clawd_path / 'memory'
    memory_dir.mkdir(exist_ok=True)
    
    cleanup_old_logs(clawd_path)
    
    # ğŸ”Œ åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨
    registry = ToolRegistry(clawd_path)
    # æ³¨å†Œ 9 ä¸ªå†…ç½®å·¥å…·
    builtin_names = [
        'readFile', 'writeFile', 'appendFile', 'listDir', 'runCmd',
        'weather', 'webSearch', 'saveMemory', 'searchMemory',
    ]
    for name in builtin_names:
        registry.register_builtin(name, name)  # handler resolved at dispatch time
    # æ‰«ææ’ä»¶å·¥å…·
    registry.scan_plugins()

    # æ¸…ç†è¿‡æœŸæ‰§è¡Œè¿½è¸ª (P2: ä¿ç•™æœ€è¿‘6ä¸ªæœˆ)
    cleanup_old_traces(clawd_path)

    ClawdDataHandler.clawd_path = clawd_path
    ClawdDataHandler.registry = registry
    
    server = HTTPServer((args.host, args.port), ClawdDataHandler)
    
    tool_names = [t['name'] for t in registry.list_all()]
    plugin_count = len(registry.plugin_tools)
    print(f"""
+==================================================================+
|              DD-OS Native Server v{VERSION}                         |
+==================================================================+
|  Mode:    NATIVE (standalone, no OpenClaw needed)                |
|  Server:  http://{args.host}:{args.port}                                    |
|  Data:    {str(clawd_path)[:50]:<50} |
+------------------------------------------------------------------+
|  Tools:   {len(tool_names)} registered ({len(builtin_names)} builtin + {plugin_count} plugins)             |
|  API:     /api/tools/execute (POST)  |  /tools (GET)            |
+==================================================================+
    """)
    
    print(f"Press Ctrl+C to stop\n")
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nShutting down...")
        server.shutdown()


if __name__ == '__main__':
    main()
