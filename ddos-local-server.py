#!/usr/bin/env python3
"""
DD-OS Native Server v3.0
ç‹¬ç«‹è¿è¡Œçš„æœ¬åœ° AI æ“ä½œç³»ç»Ÿåç«¯

åŠŸèƒ½:
    - æ–‡ä»¶æ“ä½œ (è¯»/å†™/åˆ—ç›®å½•)
    - å‘½ä»¤æ‰§è¡Œ (Shell)
    - ä»»åŠ¡ç®¡ç† (åå°æ‰§è¡Œ)
    - è®°å¿†æŒä¹…åŒ–

ç”¨æ³•:
    python ddos-local-server.py [--port 3001] [--path ~/clawd]

API:
    GET  /status              - æœåŠ¡çŠ¶æ€
    GET  /files               - åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶
    GET  /file/<name>         - è·å–æ–‡ä»¶å†…å®¹
    GET  /skills              - è·å–æŠ€èƒ½åˆ—è¡¨
    GET  /memories            - è·å–è®°å¿†æ•°æ®
    GET  /all                 - è·å–æ‰€æœ‰æ•°æ®
    POST /api/tools/execute   - æ‰§è¡Œå·¥å…· (æ–°)
    POST /task/execute        - æ‰§è¡Œä»»åŠ¡ (å…¼å®¹æ—§æ¥å£)
    GET  /task/status/<id>    - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
"""
from __future__ import annotations

import os
import sys
import re
import json
import argparse
import threading
import time
import uuid
import subprocess
import shlex
import shutil
from pathlib import Path
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from urllib.parse import unquote, urlparse, parse_qs
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, Future

# PyYAML (skill-executor/parser.py å·²ä¾èµ–)
try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False

# MCP å®¢æˆ·ç«¯æ”¯æŒ
try:
    from skills.mcp_manager import MCPClientManager
    HAS_MCP = True
except ImportError:
    HAS_MCP = False
    MCPClientManager = None

# æ–‡ä»¶è§£æ (å¯é€‰ä¾èµ–ï¼Œç¼ºå¤±æ—¶é™çº§)
try:
    import pdfplumber
    HAS_PDF = True
except ImportError:
    HAS_PDF = False

try:
    from docx import Document as DocxDocument
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

try:
    from pptx import Presentation as PptxPresentation
    HAS_PPTX = True
except ImportError:
    HAS_PPTX = False

try:
    import pytesseract
    from PIL import Image
    HAS_OCR = True
except ImportError:
    HAS_OCR = False

import base64
import io

VERSION = "4.0.0"

# ğŸ›¡ï¸ å®‰å…¨é…ç½®
DANGEROUS_COMMANDS = {'rm -rf /', 'format', 'mkfs', 'dd if=/dev/zero'}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB æœ€å¤§æ–‡ä»¶å¤§å°
MAX_OUTPUT_SIZE = 512 * 1024      # 512KB æœ€å¤§è¾“å‡º
PLUGIN_TIMEOUT = 60               # æ’ä»¶æ‰§è¡Œè¶…æ—¶(ç§’)

# ğŸŒ é™æ€æ–‡ä»¶ MIME ç±»å‹æ˜ å°„
MIME_TYPES = {
    '.html': 'text/html',
    '.css': 'text/css',
    '.js': 'application/javascript',
    '.json': 'application/json',
    '.png': 'image/png',
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.gif': 'image/gif',
    '.svg': 'image/svg+xml',
    '.ico': 'image/x-icon',
    '.woff': 'font/woff',
    '.woff2': 'font/woff2',
    '.ttf': 'font/ttf',
    '.eot': 'application/vnd.ms-fontobject',
}


# ============================================
# ğŸ§® æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®— (ç”¨äº Nexus å»é‡)
# ============================================

def calculate_text_similarity(text1: str, text2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ N-gram Jaccard ç›¸ä¼¼åº¦"""
    if not text1 or not text2:
        return 0.0
    
    def get_ngrams(text: str) -> set:
        text = text.lower()
        # æ¸…ç†ç¬¦å·ï¼Œä¿ç•™ä¸­è‹±æ–‡å’Œæ•°å­—
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
        chars = list(text.replace(' ', ''))
        if len(chars) < 2:
            return set(chars)
        # æå–å•å­—å’Œç›¸é‚»åŒå­—è¯ (Bi-gram)
        bigrams = [''.join(chars[i:i+2]) for i in range(len(chars)-1)]
        return set(chars + bigrams)
    
    set1 = get_ngrams(text1)
    set2 = get_ngrams(text2)
    if not set1 or not set2:
        return 0.0
    
    intersection = set1.intersection(set2)
    union = set1.union(set2)
    return len(intersection) / len(union)


# ============================================
# ğŸ”Œ SKILL.md Frontmatter è§£æ
# ============================================

def parse_skill_frontmatter(skill_md_path: Path) -> dict:
    """ä» SKILL.md æå– YAML frontmatter å…ƒæ•°æ®"""
    try:
        content = skill_md_path.read_text(encoding='utf-8')
    except Exception:
        return {}

    match = re.match(r'^---\s*\n(.*?)\n---\s*\n', content, re.DOTALL)
    if not match:
        # æ—  frontmatterï¼Œæå–ç¬¬ä¸€æ®µéæ ‡é¢˜æ–‡æœ¬ä½œä¸º description
        desc = ''
        for line in content.split('\n'):
            line = line.strip()
            if line and not line.startswith('#'):
                desc = line[:200]
                break
        return {'description': desc}

    if HAS_YAML:
        try:
            return yaml.safe_load(match.group(1)) or {}
        except Exception:
            return {}
    else:
        # æ—  PyYAML æ—¶ç”¨ç®€å•æ­£åˆ™æå– key: value
        result = {}
        for line in match.group(1).split('\n'):
            m = re.match(r'^(\w+)\s*:\s*(.+)$', line.strip())
            if m:
                key, val = m.group(1), m.group(2).strip()
                # ç®€å•å¤„ç†æ•°ç»„ [a, b, c]
                if val.startswith('[') and val.endswith(']'):
                    val = [v.strip().strip('"\'') for v in val[1:-1].split(',') if v.strip()]
                result[key] = val
        return result


def skill_name_to_tool_name(name: str) -> str:
    """å°† skill åç§°æ ‡å‡†åŒ–ä¸ºå·¥å…·å (kebab-case -> snake_case)"""
    return name.replace('-', '_').replace(' ', '_').lower()


# ============================================
# ğŸŒŒ NEXUS.md è§£æ
# ============================================

def parse_nexus_frontmatter(nexus_md_path: Path) -> dict:
    """ä» NEXUS.md æå– YAML frontmatter å…ƒæ•°æ®"""
    try:
        content = nexus_md_path.read_text(encoding='utf-8')
    except Exception:
        return {}

    match = re.match(r'^---\s*\n(.*?)\n---\s*\n', content, re.DOTALL)
    if not match:
        return {}

    if HAS_YAML:
        try:
            return yaml.safe_load(match.group(1)) or {}
        except Exception:
            return {}
    else:
        result = {}
        for line in match.group(1).split('\n'):
            m = re.match(r'^(\w+)\s*:\s*(.+)$', line.strip())
            if m:
                key, val = m.group(1), m.group(2).strip()
                if val.startswith('[') and val.endswith(']'):
                    val = [v.strip().strip('"\'') for v in val[1:-1].split(',') if v.strip()]
                result[key] = val
        return result


def extract_nexus_body(nexus_md_path: Path) -> str:
    """ä» NEXUS.md æå– Markdown æ­£æ–‡ (è·³è¿‡ frontmatter)"""
    try:
        content = nexus_md_path.read_text(encoding='utf-8')
    except Exception:
        return ''

    # å»æ‰ frontmatter
    match = re.match(r'^---\s*\n.*?\n---\s*\n', content, re.DOTALL)
    if match:
        return content[match.end():].strip()
    return content.strip()


def update_nexus_frontmatter(nexus_md_path: Path, updates: dict):
    """æ›´æ–° NEXUS.md çš„ frontmatter å­—æ®µ (ä¿ç•™ body ä¸å˜)"""
    body = extract_nexus_body(nexus_md_path)
    frontmatter = parse_nexus_frontmatter(nexus_md_path)
    frontmatter.update(updates)

    # é‡å»º YAML frontmatter
    lines = ['---']
    for key, val in frontmatter.items():
        if isinstance(val, list):
            lines.append(f'{key}:')
            for item in val:
                lines.append(f'  - {item}')
        elif isinstance(val, dict):
            lines.append(f'{key}:')
            for k, v in val.items():
                lines.append(f'  {k}: {v}')
        else:
            lines.append(f'{key}: {val}')
    lines.append('---')
    lines.append('')
    lines.append(body)

    nexus_md_path.write_text('\n'.join(lines), encoding='utf-8')


def count_experience_entries(exp_dir: Path) -> int:
    """ç»Ÿè®¡ç»éªŒç›®å½•ä¸­çš„æ¡ç›®æ•°ï¼Œç”¨äº XP è®¡ç®—"""
    xp = 0
    successes = exp_dir / 'successes.md'
    failures = exp_dir / 'failures.md'
    if successes.exists():
        try:
            lines = successes.read_text(encoding='utf-8').split('\n')
            xp += sum(1 for l in lines if l.startswith('### ')) * 10
        except Exception:
            pass
    if failures.exists():
        try:
            lines = failures.read_text(encoding='utf-8').split('\n')
            xp += sum(1 for l in lines if l.startswith('### ')) * 5
        except Exception:
            pass
    return xp


# ============================================
# ğŸ”Œ åŠ¨æ€å·¥å…·æ³¨å†Œè¡¨
# ============================================

class ToolRegistry:
    """åŠ¨æ€å·¥å…·å‘ç°ä¸æ³¨å†Œ - æ”¯æŒå†…ç½®å·¥å…· + æ’ä»¶å·¥å…· + æŒ‡ä»¤å‹å·¥å…· + MCPå·¥å…·"""

    def __init__(self, clawd_path: Path, project_path: Path = None):
        self.clawd_path = clawd_path
        # é¡¹ç›®ç›®å½• (è„šæœ¬æ‰€åœ¨ç›®å½•)ï¼Œç”¨äºåŠ è½½å†…ç½®æŠ€èƒ½
        self.project_path = project_path or Path(__file__).parent.resolve()
        self.builtin_tools: dict = {}      # name -> callable
        self.plugin_tools: dict = {}       # name -> ToolSpec dict (æœ‰ execute.py)
        self.instruction_tools: dict = {}  # name -> InstructionSpec (çº¯ SKILL.md)
        self.mcp_tools: dict = {}          # name -> MCPToolSpec dict (MCP æœåŠ¡å™¨)
        self.mcp_manager: 'MCPClientManager | None' = None

    def register_builtin(self, name: str, handler):
        """æ³¨å†Œå†…ç½®å·¥å…·"""
        self.builtin_tools[name] = handler

    def _get_skills_dirs(self) -> list[Path]:
        """è·å–æ‰€æœ‰æŠ€èƒ½ç›®å½• (ç”¨æˆ·ç›®å½• + é¡¹ç›®ç›®å½•)"""
        dirs = []
        # ç”¨æˆ·æ•°æ®ç›®å½•çš„æŠ€èƒ½ (ä¼˜å…ˆçº§é«˜ï¼Œå¯è¦†ç›–å†…ç½®)
        user_skills = self.clawd_path / 'skills'
        if user_skills.exists():
            dirs.append(user_skills)
        # é¡¹ç›®ç›®å½•çš„å†…ç½®æŠ€èƒ½
        project_skills = self.project_path / 'skills'
        if project_skills.exists() and project_skills != user_skills:
            dirs.append(project_skills)
        return dirs

    def scan_plugins(self):
        """é€’å½’æ‰«æ skills/ ç›®å½•ï¼Œæ³¨å†Œå¯æ‰§è¡Œæ’ä»¶ + æŒ‡ä»¤å‹æŠ€èƒ½"""
        skills_dirs = self._get_skills_dirs()
        if not skills_dirs:
            return

        plugin_count = 0
        instruction_count = 0

        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰åŒ…å« SKILL.md æˆ– manifest.json çš„ç›®å½•
        seen_dirs: set = set()
        seen_tools: set = set()  # é˜²æ­¢é‡å¤æ³¨å†ŒåŒåå·¥å…·

        for skills_dir in skills_dirs:
            # 1. å…ˆæ‰«æ manifest.json (å¯æ‰§è¡Œæ’ä»¶ä¼˜å…ˆ)
            for manifest_path in skills_dir.rglob('manifest.json'):
                skill_dir = manifest_path.parent
                dir_key = str(skill_dir.resolve())
                if dir_key in seen_dirs:
                    continue
                seen_dirs.add(dir_key)

                try:
                    spec = json.loads(manifest_path.read_text(encoding='utf-8'))

                    tools_list = spec.get('tools', [])
                    if not tools_list:
                        tools_list = [spec]

                    for tool_spec in tools_list:
                        tool_name = tool_spec.get('toolName', '')
                        executable = tool_spec.get('executable', spec.get('executable', 'execute.py'))

                        if not tool_name:
                            continue

                        # è·³è¿‡å·²æ³¨å†Œçš„åŒåå·¥å…·
                        if tool_name in seen_tools:
                            continue

                        exe_path = skill_dir / executable
                        if not exe_path.exists():
                            print(f"[ToolRegistry] Warning: {exe_path} not found, skipping {tool_name}")
                            continue

                        # å†…ç½®å·¥å…·ä¸å¯è¢«è¦†ç›–
                        if tool_name in self.builtin_tools:
                            print(f"[ToolRegistry] Warning: plugin '{tool_name}' conflicts with builtin, skipping")
                            continue

                        self.plugin_tools[tool_name] = {
                            'name': tool_name,
                            'exe_path': str(exe_path),
                            'runtime': tool_spec.get('runtime', spec.get('runtime', 'python')),
                            'inputs': tool_spec.get('inputs', {}),
                            'outputs': tool_spec.get('outputs', {}),
                            'description': tool_spec.get('description', ''),
                            'dangerLevel': tool_spec.get('dangerLevel', spec.get('dangerLevel', 'safe')),
                            'version': tool_spec.get('version', spec.get('version', '1.0.0')),
                            'skill_dir': str(skill_dir),
                            'keywords': tool_spec.get('keywords', spec.get('keywords', [])),
                        }
                        seen_tools.add(tool_name)
                        plugin_count += 1
                        print(f"[ToolRegistry] Registered plugin: {tool_name} ({exe_path.name})")

                except Exception as e:
                    print(f"[ToolRegistry] Error loading {manifest_path}: {e}")

            # 2. æ‰«æ SKILL.md (æŒ‡ä»¤å‹æŠ€èƒ½ - æ²¡æœ‰ manifest.json æˆ–æ²¡æœ‰ executable çš„)
            for skill_md in skills_dir.rglob('SKILL.md'):
                skill_dir = skill_md.parent
                dir_key = str(skill_dir.resolve())

                # å·²è¢« manifest.json æ‰«ææ³¨å†Œçš„ç›®å½•è·³è¿‡
                if dir_key in seen_dirs:
                    continue
                seen_dirs.add(dir_key)

                try:
                    frontmatter = parse_skill_frontmatter(skill_md)
                    original_name = frontmatter.get('name', skill_dir.name)
                    tool_name = skill_name_to_tool_name(original_name)

                    # å†²çªæ£€æŸ¥
                    if tool_name in self.builtin_tools or tool_name in self.plugin_tools or tool_name in seen_tools:
                        print(f"[ToolRegistry] Warning: instruction skill '{tool_name}' conflicts, skipping")
                        continue

                    self.instruction_tools[tool_name] = {
                        'name': tool_name,
                        'original_name': original_name,
                        'skill_path': str(skill_md),
                        'skill_dir': str(skill_dir),
                        'description': frontmatter.get('description', ''),
                        'inputs': frontmatter.get('inputs', {}),
                        'keywords': frontmatter.get('tags', frontmatter.get('keywords', [])),
                        'dangerLevel': 'safe',
                        'version': frontmatter.get('version', '1.0.0'),
                    }
                    seen_tools.add(tool_name)
                    instruction_count += 1
                    print(f"[ToolRegistry] Registered instruction skill: {tool_name} (from {skills_dir.name})")

                except Exception as e:
                    print(f"[ToolRegistry] Error loading {skill_md}: {e}")

        total = plugin_count + instruction_count
        if total > 0:
            print(f"[ToolRegistry] {total} tool(s) registered ({plugin_count} plugins, {instruction_count} instruction skills)")

    def scan_mcp_servers(self):
        """æ‰«æå¹¶è¿æ¥ MCP æœåŠ¡å™¨"""
        if not HAS_MCP:
            print("[ToolRegistry] MCP support not available (missing mcp_manager)")
            return

        self.mcp_manager = MCPClientManager(clawd_path=self.clawd_path)
        count = self.mcp_manager.initialize_all()

        if count > 0:
            # æ³¨å†Œ MCP å·¥å…·
            mcp_tool_count = 0
            for tool_info in self.mcp_manager.get_all_tools():
                tool_name = tool_info['name']
                # å†²çªæ£€æŸ¥
                if tool_name in self.builtin_tools or tool_name in self.plugin_tools or tool_name in self.instruction_tools:
                    print(f"[ToolRegistry] Warning: MCP tool '{tool_name}' conflicts with existing tool, skipping")
                    continue

                self.mcp_tools[tool_name] = {
                    'name': tool_name,
                    'server': tool_info.get('server', ''),
                    'description': tool_info.get('description', ''),
                    'inputs': tool_info.get('inputs', {}),
                    'dangerLevel': 'safe',
                    'version': '1.0.0',
                }
                mcp_tool_count += 1

            print(f"[ToolRegistry] {mcp_tool_count} MCP tool(s) registered from {count} server(s)")

    def is_registered(self, name: str) -> bool:
        return name in self.builtin_tools or name in self.plugin_tools or name in self.instruction_tools or name in self.mcp_tools

    def get_plugin(self, name: str) -> dict | None:
        return self.plugin_tools.get(name)

    def get_instruction(self, name: str) -> dict | None:
        return self.instruction_tools.get(name)

    def get_mcp_tool(self, name: str) -> dict | None:
        return self.mcp_tools.get(name)

    def list_all(self) -> list:
        """è¿”å›æ‰€æœ‰å·²æ³¨å†Œå·¥å…·ï¼ˆå†…ç½®+æ’ä»¶+æŒ‡ä»¤å‹+MCPï¼‰"""
        # å†…ç½®å·¥å…·å…ƒæ•°æ® (ä¸ºæœ‰ç‰¹æ®Šå‚æ•°çš„å·¥å…·æä¾›æè¿°)
        BUILTIN_META = {
            'nexusBindSkill': {
                'description': 'ä¸ºå½“å‰ Nexus ç»‘å®šæ–°æŠ€èƒ½ä¾èµ–',
                'inputs': {
                    'nexusId': {'type': 'string', 'description': 'Nexus ID', 'required': True},
                    'skillId': {'type': 'string', 'description': 'è¦ç»‘å®šçš„æŠ€èƒ½ ID', 'required': True},
                },
            },
            'nexusUnbindSkill': {
                'description': 'ä»å½“å‰ Nexus ç§»é™¤æŠ€èƒ½ä¾èµ–',
                'inputs': {
                    'nexusId': {'type': 'string', 'description': 'Nexus ID', 'required': True},
                    'skillId': {'type': 'string', 'description': 'è¦ç§»é™¤çš„æŠ€èƒ½ ID', 'required': True},
                },
            },
            'parseFile': {
                'description': 'è§£ææ–‡æ¡£æ–‡ä»¶ï¼ˆPDF/DOCX/PPTXï¼‰æˆ–å¯¹å›¾åƒè¿›è¡ŒOCRæ–‡å­—è¯†åˆ«ï¼Œè¿”å›æå–çš„æ–‡æœ¬å†…å®¹',
                'inputs': {
                    'filePath': {'type': 'string', 'description': 'æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .pdf .docx .pptx .png .jpg ç­‰æ ¼å¼ï¼‰', 'required': True},
                },
            },
            'generateSkill': {
                'description': 'åŠ¨æ€ç”Ÿæˆ Python SKILL å¹¶ä¿å­˜ã€‚å½“ç°æœ‰å·¥å…·æ— æ³•å®Œæˆä»»åŠ¡æ—¶ï¼Œç”¨æ­¤å·¥å…·åˆ›å»ºæ–°èƒ½åŠ›',
                'inputs': {
                    'name': {'type': 'string', 'description': 'æŠ€èƒ½åç§° (kebab-caseï¼Œå¦‚ ppt-maker)', 'required': True},
                    'description': {'type': 'string', 'description': 'æŠ€èƒ½åŠŸèƒ½æè¿°', 'required': True},
                    'pythonCode': {'type': 'string', 'description': 'Python å®ç°ä»£ç ï¼ˆå¿…é¡»åŒ…å« main() å‡½æ•°ï¼‰', 'required': True},
                    'nexusId': {'type': 'string', 'description': 'å…³è”çš„ Nexus IDï¼ˆå¯é€‰ï¼ŒæŒ‡å®šåä¿å­˜åˆ° Nexus ç›®å½•ï¼‰', 'required': False},
                    'triggers': {'type': 'array', 'description': 'è§¦å‘å…³é”®è¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰', 'required': False},
                },
            },
        }
        tools = []
        for name in self.builtin_tools:
            meta = BUILTIN_META.get(name, {})
            tools.append({'name': name, 'type': 'builtin', **meta})
        for name, spec in self.plugin_tools.items():
            tools.append({
                'name': name,
                'type': 'plugin',
                'description': spec.get('description', ''),
                'inputs': spec.get('inputs', {}),
                'dangerLevel': spec.get('dangerLevel', 'safe'),
                'version': spec.get('version', '1.0.0'),
            })
        for name, spec in self.instruction_tools.items():
            tools.append({
                'name': name,
                'type': 'instruction',
                'description': spec.get('description', ''),
                'inputs': spec.get('inputs', {}),
                'dangerLevel': 'safe',
                'version': spec.get('version', '1.0.0'),
            })
        for name, spec in self.mcp_tools.items():
            tools.append({
                'name': name,
                'type': 'mcp',
                'server': spec.get('server', ''),
                'description': spec.get('description', ''),
                'inputs': spec.get('inputs', {}),
                'dangerLevel': 'safe',
                'version': '1.0.0',
            })
        return tools


# ============================================
# ğŸ¤– å­ä»£ç†ç®¡ç†å™¨ (Quest æ¨¡å¼æ”¯æŒ)
# ============================================

class SubagentManager:
    """
    å­ä»£ç†ç®¡ç†å™¨ - æ”¯æŒå¹¶è¡Œæ¢ç´¢ä»»åŠ¡
    ç”¨äº Quest æ¨¡å¼çš„æ¢ç´¢é˜¶æ®µï¼Œå¯åŒæ—¶è¿è¡Œå¤šä¸ªè½»é‡çº§ä»£ç†
    """
    MAX_CONCURRENT = 5  # æœ€å¤§å¹¶å‘æ•°
    AGENT_TIMEOUT = 30  # å•ä¸ªä»£ç†è¶…æ—¶(ç§’)
    
    def __init__(self, tool_registry: ToolRegistry):
        self.registry = tool_registry
        self.agents: dict[str, dict] = {}  # agent_id -> agent_info
        self.executor = ThreadPoolExecutor(max_workers=self.MAX_CONCURRENT)
        self.futures: dict[str, Future] = {}  # agent_id -> Future
        self.lock = threading.Lock()
    
    def spawn(self, agent_type: str, task: str, tools: list[str], context: str = '') -> str:
        """
        å¯åŠ¨ä¸€ä¸ªå­ä»£ç†
        
        Args:
            agent_type: ä»£ç†ç±»å‹ ('explore', 'plan', 'execute')
            task: ä»»åŠ¡æè¿°
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            agent_id: ä»£ç† ID
        """
        agent_id = f"subagent-{int(time.time()*1000)}-{uuid.uuid4().hex[:6]}"
        
        agent_info = {
            'id': agent_id,
            'type': agent_type,
            'task': task,
            'tools': tools,
            'context': context,
            'status': 'pending',
            'result': None,
            'error': None,
            'started_at': time.time(),
            'completed_at': None,
        }
        
        with self.lock:
            # æ£€æŸ¥å¹¶å‘é™åˆ¶
            running_count = sum(1 for a in self.agents.values() if a['status'] == 'running')
            if running_count >= self.MAX_CONCURRENT:
                agent_info['status'] = 'queued'
                agent_info['error'] = f'Queue full, max {self.MAX_CONCURRENT} concurrent agents'
                self.agents[agent_id] = agent_info
                return agent_id
            
            self.agents[agent_id] = agent_info
        
        # å¼‚æ­¥æ‰§è¡Œ
        future = self.executor.submit(self._run_agent, agent_id, task, tools, context)
        self.futures[agent_id] = future
        
        with self.lock:
            self.agents[agent_id]['status'] = 'running'
        
        print(f"[SubagentManager] Spawned {agent_type} agent: {agent_id}")
        return agent_id
    
    def _run_agent(self, agent_id: str, task: str, tools: list[str], context: str) -> str:
        """
        æ‰§è¡Œå­ä»£ç†ä»»åŠ¡ (ç®€åŒ–ç‰ˆ - å•å·¥å…·è°ƒç”¨)
        
        å¯¹äºæ¢ç´¢é˜¶æ®µï¼Œæ¯ä¸ªå­ä»£ç†é€šå¸¸åªéœ€è¦è°ƒç”¨ä¸€ä¸ªå·¥å…·
        """
        try:
            result_parts = []
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©å·¥å…·
            for tool_name in tools:
                if not self.registry.is_registered(tool_name):
                    continue
                
                # æ„å»ºå·¥å…·å‚æ•°
                args = self._build_tool_args(tool_name, task, context)
                
                # æ‰§è¡Œå·¥å…·
                tool_result = self._execute_tool(tool_name, args)
                
                if tool_result.get('status') == 'success':
                    result_parts.append(f"[{tool_name}] {tool_result.get('result', '')[:1000]}")
                else:
                    result_parts.append(f"[{tool_name}] Error: {tool_result.get('result', 'Unknown error')[:200]}")
            
            final_result = '\n\n'.join(result_parts) if result_parts else 'No tools executed'
            
            with self.lock:
                if agent_id in self.agents:
                    self.agents[agent_id]['status'] = 'completed'
                    self.agents[agent_id]['result'] = final_result
                    self.agents[agent_id]['completed_at'] = time.time()
            
            return final_result
            
        except Exception as e:
            error_msg = str(e)
            with self.lock:
                if agent_id in self.agents:
                    self.agents[agent_id]['status'] = 'failed'
                    self.agents[agent_id]['error'] = error_msg
                    self.agents[agent_id]['completed_at'] = time.time()
            return f"Error: {error_msg}"
    
    def _build_tool_args(self, tool_name: str, task: str, context: str) -> dict:
        """æ ¹æ®å·¥å…·ç±»å‹æ„å»ºå‚æ•°"""
        # MCP quest å·¥å…·çš„ç‰¹æ®Šå¤„ç†
        if tool_name == 'mcp__quest__search_codebase':
            # æå–å…³é”®è¯
            keywords = self._extract_keywords(task)
            return {
                'query': task,
                'key_words': ','.join(keywords[:3]),
                'explanation': f'Exploring: {task[:50]}'
            }
        elif tool_name == 'mcp__quest__search_symbol':
            # ä»ä»»åŠ¡ä¸­æå–ç¬¦å·å
            symbols = self._extract_symbols(task)
            return {
                'queries': [{'symbol': s, 'relation': 'all'} for s in symbols[:2]],
                'explanation': f'Symbol search for: {task[:50]}'
            }
        elif tool_name == 'readFile':
            # ä»ä¸Šä¸‹æ–‡ä¸­æå–æ–‡ä»¶è·¯å¾„
            paths = self._extract_file_paths(context)
            return {'path': paths[0] if paths else ''}
        elif tool_name == 'listDir':
            return {'path': '.', 'recursive': False}
        else:
            return {'query': task}
    
    def _extract_keywords(self, text: str) -> list[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
        # ç®€å•å®ç°ï¼šæå–è‹±æ–‡å•è¯å’Œä¸­æ–‡è¯ç»„
        words = re.findall(r'[a-zA-Z_][a-zA-Z0-9_]*|[\u4e00-\u9fff]+', text)
        # è¿‡æ»¤å¸¸è§è¯
        stopwords = {'the', 'a', 'an', 'is', 'are', 'to', 'for', 'of', 'in', 'on', 'with', 'çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'äº†'}
        return [w for w in words if w.lower() not in stopwords and len(w) > 1][:5]
    
    def _extract_symbols(self, text: str) -> list[str]:
        """ä»æ–‡æœ¬ä¸­æå–å¯èƒ½çš„ç¬¦å·åï¼ˆå‡½æ•°åã€ç±»åç­‰ï¼‰"""
        # åŒ¹é…é©¼å³°å‘½åå’Œä¸‹åˆ’çº¿å‘½å
        symbols = re.findall(r'\b([A-Z][a-zA-Z0-9]*|[a-z][a-zA-Z0-9]*(?:_[a-zA-Z0-9]+)+)\b', text)
        return list(set(symbols))[:3]
    
    def _extract_file_paths(self, text: str) -> list[str]:
        """ä»æ–‡æœ¬ä¸­æå–æ–‡ä»¶è·¯å¾„"""
        paths = re.findall(r'[a-zA-Z0-9_./\\-]+\.[a-zA-Z]+', text)
        return paths[:3]
    
    def _execute_tool(self, tool_name: str, args: dict) -> dict:
        """æ‰§è¡Œå•ä¸ªå·¥å…·"""
        # æ£€æŸ¥ MCP å·¥å…·
        if tool_name.startswith('mcp__') and self.registry.mcp_manager:
            try:
                result = self.registry.mcp_manager.call_tool(tool_name, args)
                return {'status': 'success', 'result': str(result)[:2000]}
            except Exception as e:
                return {'status': 'error', 'result': str(e)}
        
        # å†…ç½®å·¥å…·éœ€è¦é€šè¿‡ handler æ‰§è¡Œï¼Œè¿™é‡Œè¿”å›å ä½
        return {'status': 'error', 'result': f'Tool {tool_name} not directly executable in subagent'}
    
    def get_status(self, agent_id: str) -> dict | None:
        """è·å–å­ä»£ç†çŠ¶æ€"""
        with self.lock:
            return self.agents.get(agent_id)
    
    def get_all_status(self) -> list[dict]:
        """è·å–æ‰€æœ‰å­ä»£ç†çŠ¶æ€"""
        with self.lock:
            return list(self.agents.values())
    
    def collect_results(self, agent_ids: list[str], timeout: float = 60.0) -> list[dict]:
        """
        æ”¶é›†å¤šä¸ªå­ä»£ç†çš„ç»“æœ
        
        Args:
            agent_ids: è¦æ”¶é›†çš„ä»£ç† ID åˆ—è¡¨
            timeout: ç­‰å¾…è¶…æ—¶æ—¶é—´(ç§’)
        
        Returns:
            ç»“æœåˆ—è¡¨
        """
        results = []
        deadline = time.time() + timeout
        
        for agent_id in agent_ids:
            remaining = deadline - time.time()
            if remaining <= 0:
                break
            
            future = self.futures.get(agent_id)
            if future:
                try:
                    future.result(timeout=remaining)
                except Exception:
                    pass
            
            with self.lock:
                agent = self.agents.get(agent_id)
                if agent:
                    results.append({
                        'id': agent_id,
                        'type': agent['type'],
                        'task': agent['task'],
                        'status': agent['status'],
                        'result': agent.get('result'),
                        'error': agent.get('error'),
                    })
        
        return results
    
    def cleanup_old_agents(self, max_age: float = 300.0):
        """æ¸…ç†è¶…è¿‡æŒ‡å®šæ—¶é—´çš„æ—§ä»£ç†è®°å½•"""
        cutoff = time.time() - max_age
        with self.lock:
            to_remove = [
                aid for aid, agent in self.agents.items()
                if agent.get('completed_at', 0) < cutoff and agent['status'] in ('completed', 'failed')
            ]
            for aid in to_remove:
                del self.agents[aid]
                self.futures.pop(aid, None)
        
        if to_remove:
            print(f"[SubagentManager] Cleaned up {len(to_remove)} old agents")


class ClawdDataHandler(BaseHTTPRequestHandler):
    clawd_path = None
    project_path = None  # é¡¹ç›®ç›®å½•ï¼Œç”¨äºåŠ è½½å†…ç½®æŠ€èƒ½
    registry = None  # type: ToolRegistry
    subagent_manager = None  # type: SubagentManager
    tasks = {}
    tasks_lock = threading.Lock()
    
    def log_message(self, format, *args):
        timestamp = datetime.now().strftime('%H:%M:%S')
        print(f"[{timestamp}] {format % args}")
    
    def send_cors_headers(self):
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
    
    def send_json(self, data, status=200):
        self.send_response(status)
        self.send_header('Content-Type', 'application/json')
        self.send_cors_headers()
        self.end_headers()
        self.wfile.write(json.dumps(data, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def send_text(self, text, status=200):
        self.send_response(status)
        self.send_header('Content-Type', 'text/plain; charset=utf-8')
        self.send_cors_headers()
        self.end_headers()
        self.wfile.write(text.encode('utf-8'))
    
    def send_error_json(self, message, status=404):
        self.send_json({'error': message, 'status': 'error'}, status)
    
    def do_OPTIONS(self):
        self.send_response(200)
        self.send_cors_headers()
        self.end_headers()
    
    def do_GET(self):
        parsed = urlparse(self.path)
        path = unquote(parsed.path)
        query = parse_qs(parsed.query)
        
        routes = {
            '/status': self.handle_status,
            '/files': self.handle_files,
            '/skills': self.handle_skills,
            '/nexuses': self.handle_nexuses,
            '/memories': self.handle_memories,
            '/tools': self.handle_tools_list,
            '/all': self.handle_all,
            '/': self.handle_index,
            '': self.handle_index,
        }
        
        if path in routes:
            routes[path]()
        elif path.startswith('/file/'):
            self.handle_file(path[6:])
        elif path.startswith('/nexuses/') and '/experience' not in path:
            nexus_name = path[9:]  # strip '/nexuses/'
            if nexus_name == 'health':
                self.handle_nexuses_health()
            else:
                self.handle_nexus_detail(nexus_name)
        elif path.startswith('/task/status/'):
            task_id = path[13:]
            offset = int(query.get('offset', ['0'])[0])
            self.handle_task_status(task_id, offset)
        elif path == '/api/traces/search':
            self.handle_trace_search(query)
        elif path == '/api/traces/recent':
            self.handle_trace_recent(query)
        elif path == '/api/registry/skills':
            self.handle_registry_skills_search(query)
        elif path == '/api/registry/mcp':
            self.handle_registry_mcp_search(query)
        elif path == '/mcp/servers':
            self.handle_mcp_servers_list()
        elif path.startswith('/data/'):
            # å‰ç«¯æ•°æ®è¯»å– API
            key = path[6:]  # strip '/data/'
            self.handle_data_get(key)
        elif path == '/data':
            # åˆ—å‡ºæ‰€æœ‰æ•°æ®é”®
            self.handle_data_list()
        else:
            # é™æ€æ–‡ä»¶æœåŠ¡ (æ‰˜ç®¡ dist/ ç›®å½•)
            self.serve_static_file(path)
    
    def do_POST(self):
        parsed = urlparse(self.path)
        path = unquote(parsed.path)
        content_type = self.headers.get('Content-Type', '')
        
        # æ–‡ä»¶ä¸Šä¼ ï¼šmultipart/form-data å•ç‹¬å¤„ç†ï¼ˆé¿å…å¤§æ–‡ä»¶ JSON ç¼–ç  OOMï¼‰
        if path == '/api/files/upload' and 'multipart/form-data' in content_type:
            self.handle_file_upload_multipart()
            return
        
        content_length = int(self.headers.get('Content-Length', 0))
        body = self.rfile.read(content_length).decode('utf-8') if content_length > 0 else '{}'
        
        try:
            data = json.loads(body) if body else {}
        except json.JSONDecodeError:
            self.send_error_json('Invalid JSON', 400)
            return
        
        # ğŸŒŸ æ–°å¢ï¼šå·¥å…·æ‰§è¡Œæ¥å£
        if path == '/api/tools/execute':
            self.handle_tool_execution(data)
        elif path == '/api/files/upload':
            self.handle_file_upload(data)
        elif path == '/tools/reload':
            self.handle_tools_reload(data)
        elif path == '/api/traces/save':
            self.handle_trace_save(data)
        elif path == '/mcp/reload':
            self.handle_mcp_reload(data)
        elif path.startswith('/mcp/servers/') and path.endswith('/reconnect'):
            server_name = path[13:-10]  # Extract server name
            self.handle_mcp_reconnect(server_name)
        elif path == '/mcp/install':
            self.handle_mcp_install(data)
        elif path == '/skills/install':
            self.handle_skill_install(data)
        elif path == '/skills/uninstall':
            self.handle_skill_uninstall(data)
        elif path.startswith('/nexuses/') and path.endswith('/skills'):
            nexus_name = path[9:-7]  # strip '/nexuses/' and '/skills'
            self.handle_nexus_update_skills(nexus_name, data)
        elif path.startswith('/nexuses/') and path.endswith('/experience'):
            nexus_name = path[9:-11]  # strip '/nexuses/' and '/experience'
            self.handle_add_experience(nexus_name, data)
        elif path.startswith('/nexuses/') and path.endswith('/meta'):
            nexus_name = path[9:-5]  # strip '/nexuses/' and '/meta'
            self.handle_nexus_update_meta(nexus_name, data)
        elif path == '/task/execute':
            self.handle_task_execute(data)
        elif path.startswith('/data/'):
            # å‰ç«¯æ•°æ®å†™å…¥ API
            key = path[6:]  # strip '/data/'
            self.handle_data_set(key, data)
        # ğŸ¤– å­ä»£ç† API (Quest æ¨¡å¼æ”¯æŒ)
        elif path == '/api/subagent/spawn':
            self.handle_subagent_spawn(data)
        elif path == '/api/subagent/collect':
            self.handle_subagent_collect(data)
        elif path.startswith('/api/subagent/') and path.endswith('/status'):
            agent_id = path[14:-7]  # strip '/api/subagent/' and '/status'
            self.handle_subagent_status(agent_id)
        else:
            self.send_error_json(f'Unknown endpoint: {path}', 404)
    
    # ============================================
    # ğŸŒ é™æ€æ–‡ä»¶æœåŠ¡ (æ‰˜ç®¡å‰ç«¯ dist/)
    # ============================================
    
    def serve_static_file(self, path: str):
        """æ‰˜ç®¡ dist/ ç›®å½•çš„å‰ç«¯æ„å»ºäº§ç‰©ï¼Œæ”¯æŒ SPA è·¯ç”±"""
        # é™æ€æ–‡ä»¶ç›®å½• (ä¸æœåŠ¡å™¨è„šæœ¬åŒçº§çš„ dist/)
        static_dir = Path(__file__).parent / 'dist'
        
        if not static_dir.exists():
            # dist/ ä¸å­˜åœ¨æ—¶è¿”å›æç¤º
            self.send_response(200)
            self.send_header('Content-Type', 'text/html; charset=utf-8')
            self.end_headers()
            self.wfile.write(b'''<!DOCTYPE html>
<html>
<head><title>DD-OS Server</title></head>
<body style="font-family: system-ui; padding: 40px; background: #1a1a2e; color: #eee;">
<h1>DD-OS Native Server</h1>
<p>Frontend not built. Run <code>npm run build</code> to generate dist/</p>
<p>Or access dev server at <a href="http://localhost:5173">http://localhost:5173</a></p>
<hr>
<p>API Endpoints:</p>
<ul>
<li>GET /status - Server status</li>
<li>GET /skills - List skills</li>
<li>POST /api/tools/execute - Execute tool</li>
</ul>
</body>
</html>''')
            return
        
        # ç¡®å®šæ–‡ä»¶è·¯å¾„
        if path == '/' or path == '':
            file_path = static_dir / 'index.html'
        else:
            # å»æ‰å¼€å¤´çš„ /
            clean_path = path.lstrip('/')
            file_path = static_dir / clean_path
        
        # SPA è·¯ç”±æ”¯æŒï¼šå¦‚æœä¸æ˜¯æ–‡ä»¶ï¼ˆæ²¡æœ‰æ‰©å±•åï¼‰ï¼Œè¿”å› index.html
        if not file_path.exists():
            if '.' not in file_path.name:
                file_path = static_dir / 'index.html'
        
        if not file_path.exists():
            self.send_error_json(f'File not found: {path}', 404)
            return
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è·¯å¾„åœ¨ static_dir å†…
        try:
            file_path.resolve().relative_to(static_dir.resolve())
        except ValueError:
            self.send_error_json('Access denied', 403)
            return
        
        # è·å– MIME ç±»å‹
        suffix = file_path.suffix.lower()
        content_type = MIME_TYPES.get(suffix, 'application/octet-stream')
        
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
            
            self.send_response(200)
            self.send_header('Content-Type', content_type)
            self.send_header('Content-Length', str(len(content)))
            # ç¼“å­˜æ§åˆ¶ï¼šé™æ€èµ„æºé•¿æœŸç¼“å­˜
            if '/assets/' in str(file_path):
                self.send_header('Cache-Control', 'public, max-age=31536000')
            self.end_headers()
            self.wfile.write(content)
        except Exception as e:
            self.send_error_json(f'Failed to read file: {str(e)}', 500)
    
    # ============================================
    # ğŸ“¦ å‰ç«¯æ•°æ®æŒä¹…åŒ– API (/data)
    # ============================================
    
    def handle_data_get(self, key: str):
        """è¯»å–å‰ç«¯æ•°æ®"""
        data_dir = self.clawd_path / 'data'
        data_dir.mkdir(exist_ok=True)
        
        # å®‰å…¨æ£€æŸ¥ï¼škey åªèƒ½æ˜¯å­—æ¯æ•°å­—ä¸‹åˆ’çº¿
        if not re.match(r'^[a-zA-Z0-9_-]+$', key):
            self.send_error_json('Invalid key format', 400)
            return
        
        file_path = data_dir / f'{key}.json'
        
        if not file_path.exists():
            self.send_json({'key': key, 'value': None, 'exists': False})
            return
        
        try:
            content = file_path.read_text(encoding='utf-8')
            self.send_json({'key': key, 'value': json.loads(content), 'exists': True})
        except Exception as e:
            self.send_error_json(f'Failed to read data: {str(e)}', 500)
    
    def handle_data_set(self, key: str, data: dict):
        """å†™å…¥å‰ç«¯æ•°æ®"""
        data_dir = self.clawd_path / 'data'
        data_dir.mkdir(exist_ok=True)
        
        # å®‰å…¨æ£€æŸ¥ï¼škey åªèƒ½æ˜¯å­—æ¯æ•°å­—ä¸‹åˆ’çº¿
        if not re.match(r'^[a-zA-Z0-9_-]+$', key):
            self.send_error_json('Invalid key format', 400)
            return
        
        file_path = data_dir / f'{key}.json'
        value = data.get('value')
        
        try:
            if value is None:
                # åˆ é™¤æ•°æ®
                if file_path.exists():
                    file_path.unlink()
                self.send_json({'key': key, 'deleted': True})
            else:
                # å†™å…¥æ•°æ®
                file_path.write_text(json.dumps(value, ensure_ascii=False, indent=2), encoding='utf-8')
                self.send_json({'key': key, 'saved': True})
        except Exception as e:
            self.send_error_json(f'Failed to save data: {str(e)}', 500)
    
    def handle_data_list(self):
        """åˆ—å‡ºæ‰€æœ‰æ•°æ®é”®"""
        data_dir = self.clawd_path / 'data'
        data_dir.mkdir(exist_ok=True)
        
        keys = []
        for f in data_dir.glob('*.json'):
            keys.append(f.stem)
        
        self.send_json({'keys': keys})
    
    # ============================================
    # ğŸ› ï¸ å·¥å…·æ‰§è¡Œ (æ ¸å¿ƒæ–°åŠŸèƒ½)
    # ============================================
    
    def handle_tool_execution(self, data):
        """å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚ - æ”¯æŒå†…ç½®å·¥å…·ã€æ’ä»¶å·¥å…·ã€æŒ‡ä»¤å‹å·¥å…·å’ŒMCPå·¥å…·"""
        tool_name = data.get('name', '')
        args = data.get('args', {})

        if not self.registry.is_registered(tool_name):
            all_tools = [t['name'] for t in self.registry.list_all()]
            self.send_json({
                'tool': tool_name,
                'status': 'error',
                'result': f'Tool not registered: {tool_name}. Available: {", ".join(all_tools)}'
            }, 403)
            return

        result = ""
        status = "success"

        try:
            # 1. æŒ‡ä»¤å‹å·¥å…· -> è·¯ç”±åˆ° skill-executor
            instruction_spec = self.registry.get_instruction(tool_name)
            if instruction_spec:
                result = self._execute_instruction_tool(instruction_spec, tool_name, args)
            # 2. æ’ä»¶å·¥å…· -> subprocess æ‰§è¡Œ
            elif self.registry.get_plugin(tool_name):
                plugin_spec = self.registry.get_plugin(tool_name)
                result = self._execute_plugin_tool(plugin_spec, tool_name, args)
            # 3. MCP å·¥å…· -> é€šè¿‡ MCPManager è°ƒç”¨
            elif self.registry.get_mcp_tool(tool_name):
                result = self._execute_mcp_tool(tool_name, args)
            # 4. å†…ç½®å·¥å…· -> ç›´æ¥è°ƒåº¦
            else:
                builtin_handlers = {
                    'readFile': self._tool_read_file,
                    'writeFile': self._tool_write_file,
                    'appendFile': self._tool_append_file,
                    'listDir': self._tool_list_dir,
                    'runCmd': self._tool_run_cmd,
                    'weather': self._tool_weather,
                    'webSearch': self._tool_web_search,
                    'webFetch': self._tool_web_fetch,
                    'saveMemory': self._tool_save_memory,
                    'searchMemory': self._tool_search_memory,
                    'nexusBindSkill': self._tool_nexus_bind_skill,
                    'nexusUnbindSkill': self._tool_nexus_unbind_skill,
                    'openInExplorer': self._tool_open_in_explorer,
                    'parseFile': self._tool_parse_file,
                    'generateSkill': self._tool_generate_skill,
                }
                handler = builtin_handlers.get(tool_name)
                if handler:
                    result = handler(args)
                else:
                    raise ValueError(f"No handler for builtin tool: {tool_name}")

        except Exception as e:
            status = "error"
            result = f"Tool execution failed: {str(e)}"

        self.send_json({
            'tool': tool_name,
            'status': status,
            'result': result,
            'timestamp': datetime.now().isoformat()
        })

    # ============================================
    # ğŸ“ æ–‡ä»¶ä¸Šä¼  + è‡ªåŠ¨è§£æ
    # ============================================

    UPLOAD_ALLOWED_EXT = {'.pdf', '.docx', '.pptx', '.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp', '.txt', '.md', '.csv'}

    def handle_file_upload_multipart(self):
        """æ¥æ”¶ FormData multipart ä¸Šä¼ ï¼Œä¿å­˜å¹¶è‡ªåŠ¨è§£æ
        
        ä½¿ç”¨æ‰‹åŠ¨ multipart boundary è§£æï¼Œä¸ä¾èµ–å·²åºŸå¼ƒçš„ cgi.FieldStorage
        ï¼ˆcgi åœ¨ Python 3.11+ deprecatedï¼Œ3.13 removedï¼‰
        """
        content_type = self.headers.get('Content-Type', '')
        content_length = int(self.headers.get('Content-Length', 0))

        if content_length > MAX_FILE_SIZE:
            # æ¶ˆè€—è¯·æ±‚ä½“é¿å…è¿æ¥å¼‚å¸¸
            remaining = content_length
            while remaining > 0:
                chunk = min(remaining, 65536)
                self.rfile.read(chunk)
                remaining -= chunk
            self.send_error_json(f'æ–‡ä»¶è¿‡å¤§ (>{MAX_FILE_SIZE // 1024 // 1024}MB)', 413)
            return

        # ä» Content-Type æå– boundary
        boundary = None
        for part in content_type.split(';'):
            part = part.strip()
            if part.startswith('boundary='):
                boundary = part[len('boundary='):].strip('"')
        if not boundary:
            self.send_error_json('æ— æ•ˆçš„ multipart è¯·æ±‚ï¼šç¼ºå°‘ boundary', 400)
            return

        # è¯»å–æ•´ä¸ªè¯·æ±‚ä½“ï¼ˆå·²éªŒè¯ content_length <= 10MBï¼Œå†…å­˜å®‰å…¨ï¼‰
        try:
            raw_body = self.rfile.read(content_length)
        except Exception as e:
            print(f"[ERROR] è¯»å–è¯·æ±‚ä½“å¤±è´¥: {e}", file=sys.stderr)
            self.send_error_json('è¯»å–ä¸Šä¼ æ•°æ®å¤±è´¥', 400)
            return

        # æŒ‰ boundary åˆ†å‰²ï¼Œæå–åŒ…å« filename çš„ part
        boundary_bytes = ('--' + boundary).encode()
        parts = raw_body.split(boundary_bytes)

        file_bytes = None
        file_name = 'unknown'
        for part_data in parts:
            if b'filename=' not in part_data:
                continue
            # headers å’Œ body ä»¥ç©ºè¡Œ (\r\n\r\n) åˆ†éš”
            header_end = part_data.find(b'\r\n\r\n')
            if header_end == -1:
                continue
            headers_raw_bytes = part_data[:header_end]
            # å°è¯• UTF-8ï¼ˆæµè§ˆå™¨ FormDataï¼‰ï¼Œå›é€€åˆ° GBKï¼ˆWindows curl/å·¥å…·ï¼‰
            try:
                headers_raw = headers_raw_bytes.decode('utf-8')
            except UnicodeDecodeError:
                headers_raw = headers_raw_bytes.decode('gbk', errors='replace')
            file_bytes = part_data[header_end + 4:]
            # å»æ‰å°¾éƒ¨çš„ \r\nï¼ˆmultipart æ ¼å¼çº¦å®šï¼‰
            if file_bytes.endswith(b'\r\n'):
                file_bytes = file_bytes[:-2]
            # ä» Content-Disposition æå– filename
            for line in headers_raw.split('\r\n'):
                if 'filename=' in line:
                    # æ”¯æŒ: filename="ä¸­æ–‡.pptx" å’Œ filename=file.pdf
                    match = re.search(r'filename="?([^";\r\n]+)"?', line)
                    if match:
                        file_name = match.group(1).strip()
            break  # åªå–ç¬¬ä¸€ä¸ªæ–‡ä»¶

        if file_bytes is None:
            self.send_error_json('æœªæ‰¾åˆ°ä¸Šä¼ æ–‡ä»¶', 400)
            return

        # æ¸…ç†æ–‡ä»¶åï¼ˆä¿ç•™ä¸­æ–‡ã€å­—æ¯ã€æ•°å­—ã€ç‚¹ã€æ¨ªçº¿ï¼‰
        safe_name = re.sub(r'[^\w.\-\u4e00-\u9fff]', '_', file_name)
        # æ–‡ä»¶åé•¿åº¦é™åˆ¶ï¼ˆNTFS/ext4 æœ€å¤§ 255 å­—ç¬¦ï¼‰
        stem, ext = os.path.splitext(safe_name)
        ext = ext.lower()
        if len(safe_name) > 200:
            safe_name = stem[:200 - len(ext)] + ext

        if ext not in self.UPLOAD_ALLOWED_EXT:
            self.send_error_json(f'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}ï¼Œæ”¯æŒ: {", ".join(sorted(self.UPLOAD_ALLOWED_EXT))}', 400)
            return

        if len(file_bytes) > MAX_FILE_SIZE:
            self.send_error_json(f'æ–‡ä»¶è¿‡å¤§ (>{MAX_FILE_SIZE // 1024 // 1024}MB)', 413)
            return

        # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        upload_dir = self.clawd_path / 'temp' / 'uploads'
        upload_dir.mkdir(parents=True, exist_ok=True)
        unique_name = f"{uuid.uuid4().hex[:8]}_{safe_name}"
        file_path = upload_dir / unique_name

        try:
            file_path.write_bytes(file_bytes)
        except Exception as e:
            print(f"[ERROR] æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}", file=sys.stderr)
            self.send_error_json('æ–‡ä»¶ä¿å­˜å¤±è´¥', 500)
            return

        # è‡ªåŠ¨è§£æ
        parsed_text = ''
        try:
            parsed_text = self._tool_parse_file({'filePath': str(file_path)})
        except Exception as e:
            print(f"[ERROR] æ–‡ä»¶è§£æå¤±è´¥: {e}", file=sys.stderr)
            parsed_text = f'[è§£æå¤±è´¥: è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®]'

        file_size = len(file_bytes)
        self.send_json({
            'success': True,
            'filePath': str(file_path),
            'originalName': file_name,
            'fileSize': file_size,
            'parsedText': parsed_text,
            'timestamp': datetime.now().isoformat()
        })

    def handle_file_upload(self, data: dict):
        """æ¥æ”¶å‰ç«¯ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆBase64ï¼‰ï¼Œä¿å­˜åˆ°ä¸´æ—¶ç›®å½•å¹¶è‡ªåŠ¨è§£æ"""
        file_name = data.get('fileName', '')
        data_base64 = data.get('dataBase64', '')

        if not file_name or not data_base64:
            self.send_error_json('fileName and dataBase64 are required', 400)
            return

        # æ¸…ç†æ–‡ä»¶å
        safe_name = re.sub(r'[^\w.\-\u4e00-\u9fff]', '_', file_name)
        ext = os.path.splitext(safe_name)[1].lower()

        if ext not in self.UPLOAD_ALLOWED_EXT:
            self.send_error_json(f'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}ï¼Œæ”¯æŒ: {", ".join(sorted(self.UPLOAD_ALLOWED_EXT))}', 400)
            return

        # è§£ç  Base64 (å»æ‰ data:xxx;base64, å‰ç¼€)
        try:
            if ';base64,' in data_base64:
                data_base64 = data_base64.split(';base64,')[1]
            file_bytes = base64.b64decode(data_base64)
        except Exception as e:
            self.send_error_json(f'Base64 è§£ç å¤±è´¥: {str(e)}', 400)
            return

        if len(file_bytes) > MAX_FILE_SIZE:
            self.send_error_json(f'æ–‡ä»¶è¿‡å¤§ (>{MAX_FILE_SIZE // 1024 // 1024}MB)', 413)
            return

        # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        upload_dir = self.clawd_path / 'temp' / 'uploads'
        upload_dir.mkdir(parents=True, exist_ok=True)
        unique_name = f"{uuid.uuid4().hex[:8]}_{safe_name}"
        file_path = upload_dir / unique_name

        try:
            file_path.write_bytes(file_bytes)
        except Exception as e:
            self.send_error_json(f'æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}', 500)
            return

        # è‡ªåŠ¨è§£æ
        parsed_text = ''
        try:
            parsed_text = self._tool_parse_file({'filePath': str(file_path)})
        except Exception as e:
            parsed_text = f'[è§£æå¤±è´¥: {str(e)}]'

        self.send_json({
            'success': True,
            'filePath': str(file_path),
            'originalName': file_name,
            'parsedText': parsed_text,
            'timestamp': datetime.now().isoformat()
        })

    def _execute_plugin_tool(self, spec: dict, tool_name: str, args: dict) -> str:
        """æ‰§è¡Œæ’ä»¶å·¥å…· - subprocess éš”ç¦»æ‰§è¡Œ"""
        exe_path = spec['exe_path']
        runtime = spec.get('runtime', 'python')

        # ç¡®å®šè¿è¡Œæ—¶å‘½ä»¤
        if runtime == 'python':
            cmd = [sys.executable, exe_path]
        elif runtime == 'node':
            cmd = ['node', exe_path]
        else:
            raise ValueError(f"Unsupported runtime: {runtime}")

        # æ„å»ºè¾“å…¥ï¼šåŒ…å«å·¥å…·åå’Œå‚æ•°ï¼ˆæ”¯æŒå¤šå·¥å…· manifestï¼‰
        input_data = json.dumps({
            'tool': tool_name,
            'args': args
        }, ensure_ascii=False)

        try:
            process = subprocess.run(
                cmd,
                input=input_data,
                capture_output=True,
                text=True,
                timeout=PLUGIN_TIMEOUT,
                cwd=spec.get('skill_dir', str(self.clawd_path)),
            )

            if process.returncode != 0:
                stderr = process.stderr[:MAX_OUTPUT_SIZE] if process.stderr else ''
                raise RuntimeError(f"Plugin exited with code {process.returncode}: {stderr}")

            return process.stdout[:MAX_OUTPUT_SIZE] if process.stdout else ''

        except subprocess.TimeoutExpired:
            raise RuntimeError(f"Plugin timed out after {PLUGIN_TIMEOUT}s")

    def _execute_instruction_tool(self, spec: dict, tool_name: str, args: dict) -> str:
        """æ‰§è¡ŒæŒ‡ä»¤å‹å·¥å…· - é€šè¿‡ skill-executor è§£æ SKILL.md å¹¶è¿”å›æŒ‡ä»¤"""
        skill_executor = self.clawd_path / 'skills' / 'skill-executor' / 'execute.py'

        if not skill_executor.exists():
            raise RuntimeError(f"skill-executor not found at {skill_executor}")

        # ä½¿ç”¨ original_name (kebab-case) è®© SkillDiscovery èƒ½æ‰¾åˆ°ç›®å½•
        original_name = spec.get('original_name', tool_name)

        input_data = json.dumps({
            'tool': 'run_skill',
            'args': {
                'skill_name': original_name,
                'args': args,
                'project_root': str(self.clawd_path),
            }
        }, ensure_ascii=False)

        try:
            process = subprocess.run(
                [sys.executable, str(skill_executor)],
                input=input_data,
                capture_output=True,
                text=True,
                timeout=PLUGIN_TIMEOUT,
                cwd=str(skill_executor.parent),
            )

            if process.returncode != 0:
                stderr = process.stderr[:MAX_OUTPUT_SIZE] if process.stderr else ''
                raise RuntimeError(f"Instruction skill error: {stderr}")

            result = json.loads(process.stdout)
            if not result.get('success'):
                raise RuntimeError(result.get('error', 'Unknown error'))

            return result.get('instructions', result.get('output', ''))

        except subprocess.TimeoutExpired:
            raise RuntimeError(f"Instruction skill timed out after {PLUGIN_TIMEOUT}s")
        except json.JSONDecodeError:
            # skill-executor è¿”å›é JSON æ—¶ï¼Œç›´æ¥è¿”å›åŸæ–‡
            return process.stdout[:MAX_OUTPUT_SIZE] if process.stdout else ''

    def _execute_mcp_tool(self, tool_name: str, args: dict) -> str:
        """æ‰§è¡Œ MCP å·¥å…· - é€šè¿‡ MCPManager è°ƒç”¨è¿œç¨‹ MCP æœåŠ¡å™¨"""
        if not self.registry.mcp_manager:
            raise RuntimeError("MCP manager not initialized")

        try:
            result = self.registry.mcp_manager.call_tool(tool_name, args, timeout=PLUGIN_TIMEOUT)
            if result is None:
                return ""
            return str(result)
        except Exception as e:
            raise RuntimeError(f"MCP tool execution failed: {e}")
    
    def _resolve_path(self, relative_path: str, allow_outside: bool = False) -> Path:
        """è§£æå¹¶éªŒè¯è·¯å¾„å®‰å…¨æ€§"""
        if not relative_path:
            raise ValueError("Path cannot be empty")
        
        # ç§»é™¤å¼€å¤´çš„æ–œæ 
        clean_path = relative_path.lstrip('/')
        
        # é»˜è®¤åœ¨ clawd ç›®å½•ä¸‹æ“ä½œ
        if allow_outside and os.path.isabs(relative_path):
            file_path = Path(relative_path)
        else:
            file_path = self.clawd_path / clean_path
        
        # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†
        try:
            resolved = file_path.resolve()
            if not allow_outside:
                resolved.relative_to(self.clawd_path.resolve())
        except ValueError:
            raise PermissionError(f"Access denied: path outside allowed directory")
        
        return resolved
    
    def _tool_read_file(self, args: dict) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        path = args.get('path', '')
        file_path = self._resolve_path(path, allow_outside=args.get('allowOutside', False))
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {path}")
        if not file_path.is_file():
            raise ValueError(f"Not a file: {path}")
        if file_path.stat().st_size > MAX_FILE_SIZE:
            raise ValueError(f"File too large (>{MAX_FILE_SIZE} bytes)")
        
        return file_path.read_text(encoding='utf-8')
    
    def _tool_parse_file(self, args: dict) -> str:
        """è§£ææ–‡æ¡£æˆ–å›¾åƒæ–‡ä»¶ï¼Œè¿”å›æå–çš„æ–‡æœ¬å†…å®¹"""
        file_path_str = args.get('filePath') or args.get('path', '')
        if not file_path_str:
            raise ValueError("filePath is required")
        
        # æ”¯æŒç»å¯¹è·¯å¾„ï¼ˆä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶ï¼‰å’Œç›¸å¯¹è·¯å¾„
        if os.path.isabs(file_path_str):
            file_path = Path(file_path_str).resolve()
            # å®‰å…¨æ£€æŸ¥ï¼šåªå…è®¸è®¿é—® clawd å·¥ä½œç›®å½•ä¸‹çš„æ–‡ä»¶
            allowed_root = self.clawd_path.resolve()
            try:
                file_path.relative_to(allowed_root)
            except ValueError:
                raise PermissionError(f"Access denied: path outside allowed directory")
        else:
            file_path = self._resolve_path(file_path_str, allow_outside=True)
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path_str}")
        if file_path.stat().st_size > MAX_FILE_SIZE:
            raise ValueError(f"File too large (>{MAX_FILE_SIZE // 1024 // 1024}MB)")
        
        ext = file_path.suffix.lower()
        text = ""
        
        if ext == '.pdf':
            if not HAS_PDF:
                raise RuntimeError("pdfplumber æœªå®‰è£…ï¼Œè¯·è¿è¡Œ pip install pdfplumber")
            with pdfplumber.open(str(file_path)) as pdf:
                pages = []
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text() or ''
                    if page_text.strip():
                        pages.append(f"--- ç¬¬{i+1}é¡µ ---\n{page_text}")
                text = "\n\n".join(pages)
        
        elif ext == '.docx':
            if not HAS_DOCX:
                raise RuntimeError("python-docx æœªå®‰è£…ï¼Œè¯·è¿è¡Œ pip install python-docx")
            doc = DocxDocument(str(file_path))
            paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]
            for table in doc.tables:
                for row in table.rows:
                    cells = [cell.text.strip() for cell in row.cells]
                    paragraphs.append(" | ".join(cells))
            text = "\n".join(paragraphs)
        
        elif ext == '.pptx':
            if not HAS_PPTX:
                raise RuntimeError("python-pptx æœªå®‰è£…ï¼Œè¯·è¿è¡Œ pip install python-pptx")
            prs = PptxPresentation(str(file_path))
            slides = []
            for i, slide in enumerate(prs.slides):
                parts = []
                for shape in slide.shapes:
                    if shape.has_text_frame:
                        for para in shape.text_frame.paragraphs:
                            t = para.text.strip()
                            if t:
                                parts.append(t)
                if parts:
                    slides.append(f"--- å¹»ç¯ç‰‡{i+1} ---\n" + "\n".join(parts))
            text = "\n\n".join(slides)
        
        elif ext in ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'):
            if not HAS_OCR:
                raise RuntimeError("pytesseract/Pillow æœªå®‰è£…ï¼Œè¯·è¿è¡Œ pip install pytesseract Pillow")
            img = Image.open(str(file_path))
            lang = args.get('language', 'eng+chi_sim')
            text = pytesseract.image_to_string(img, lang=lang)
        
        else:
            # å›é€€ï¼šå°è¯•å½“çº¯æ–‡æœ¬è¯»å–
            try:
                text = file_path.read_text(encoding='utf-8')
            except Exception:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}")
        
        if not text.strip():
            return f"[æ–‡ä»¶ {file_path.name} æ— å¯æå–çš„æ–‡æœ¬å†…å®¹]"
        
        # æˆªæ–­åˆ° MAX_OUTPUT_SIZEï¼ˆå®‰å…¨ UTF-8 è¾¹ç•Œæˆªæ–­ï¼‰
        encoded = text.encode('utf-8')
        if len(encoded) > MAX_OUTPUT_SIZE:
            safe_idx = MAX_OUTPUT_SIZE
            # å›é€€åˆ° UTF-8 å­—ç¬¦è¾¹ç•Œï¼Œé¿å…æˆªæ–­å¤šå­—èŠ‚å­—ç¬¦å¯¼è‡´ä¹±ç 
            while safe_idx > 0 and (encoded[safe_idx] & 0xC0) == 0x80:
                safe_idx -= 1
            text = encoded[:safe_idx].decode('utf-8')
            text += f"\n\n[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­è‡³çº¦ {MAX_OUTPUT_SIZE // 1024}KB]"
        
        return text
    
    def _tool_write_file(self, args: dict) -> str:
        """å†™å…¥æ–‡ä»¶"""
        path = args.get('path', '')
        content = args.get('content', '')
        
        file_path = self._resolve_path(path)
        
        # === Nexus æ¶Œç°å»é‡ç½‘å…³ ===
        if 'nexuses/' in path and path.endswith('NEXUS.md'):
            # ä»…åœ¨æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼ˆå³æ–°å»ºæ“ä½œï¼‰è¿›è¡Œå»é‡æ£€æŸ¥
            if not file_path.exists():
                duplicate_id = self._check_nexus_duplication(content)
                if duplicate_id:
                    return (f"ã€ç³»ç»Ÿæ‹¦æˆªã€‘åˆ›å»ºå¤±è´¥ï¼\n"
                            f"æ£€æµ‹åˆ°é«˜åº¦ç›¸ä¼¼çš„ Nexus èŠ‚ç‚¹å·²å­˜åœ¨ (èŠ‚ç‚¹ ID: {duplicate_id})ã€‚\n"
                            f"ä¸ºé¿å…çŸ¥è¯†å›¾è°±ç¢ç‰‡åŒ–ï¼Œè¯·ä¸è¦åˆ›å»ºæ–°ç›®å½•ï¼Œè¯·ç›´æ¥ä½¿ç”¨ 'readFile' å’Œ 'writeFile' "
                            f"è¯»å–å¹¶æ›´æ–°åŸæœ‰çš„ nexuses/{duplicate_id}/NEXUS.mdï¼Œæˆ–è€…å‘å…¶è¿½åŠ  experienceã€‚")
        
        # === Nexus æ ¼å¼å¼•å¯¼ ===
        # æ£€æµ‹å†™å…¥ nexuses/ ç›®å½•ä½†ä¸æ˜¯ NEXUS.md çš„æƒ…å†µï¼Œæä¾›æ ¼å¼çº æ­£æç¤º
        if 'nexuses/' in path and not path.endswith('NEXUS.md'):
            # æå–å¯èƒ½çš„ nexus id
            import re
            nexus_match = re.search(r'nexuses/([^/]+)', path)
            nexus_id = nexus_match.group(1) if nexus_match else 'your-nexus-id'
            
            # å¦‚æœæ˜¯å†™å…¥ .json æˆ–å…¶ä»–é…ç½®æ–‡ä»¶ï¼Œè¿”å›è­¦å‘Šå¹¶å¼•å¯¼æ­£ç¡®æ ¼å¼
            if path.endswith('.json') or (path.endswith('.md') and 'NEXUS.md' not in path):
                return (f"ã€æ ¼å¼æç¤ºã€‘æ£€æµ‹åˆ°ä½ æ­£åœ¨å‘ nexuses/ ç›®å½•å†™å…¥éæ ‡å‡†æ–‡ä»¶ã€‚\n\n"
                        f"âš ï¸ Nexus åªèƒ½é€šè¿‡ NEXUS.md æ–‡ä»¶å®šä¹‰ï¼Œç³»ç»Ÿä¸ä¼šè¯†åˆ« .json æˆ–å…¶ä»– .md æ–‡ä»¶ï¼\n\n"
                        f"ğŸ“ æ­£ç¡®åšæ³•ï¼šè¯·åˆ›å»º nexuses/{nexus_id}/NEXUS.md æ–‡ä»¶ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
                        f"```markdown\n"
                        f"---\n"
                        f"name: Nexusåç§°\n"
                        f"description: åŠŸèƒ½æè¿°\n"
                        f"version: 1.0.0\n"
                        f"skill_dependencies:\n"
                        f"  - æŠ€èƒ½ID\n"
                        f"tags:\n"
                        f"  - æ ‡ç­¾\n"
                        f"triggers:\n"
                        f"  - è§¦å‘è¯\n"
                        f"objective: æ ¸å¿ƒç›®æ ‡\n"
                        f"metrics:\n"
                        f"  - è´¨é‡æŒ‡æ ‡\n"
                        f"strategy: æ‰§è¡Œç­–ç•¥\n"
                        f"---\n\n"
                        f"# Nexusåç§° SOP\n\n"
                        f"ï¼ˆè¯¦ç»†çš„æ ‡å‡†ä½œä¸šç¨‹åºï¼‰\n"
                        f"```\n\n"
                        f"è¯·ä½¿ç”¨æ­£ç¡®æ ¼å¼é‡æ–°åˆ›å»º nexuses/{nexus_id}/NEXUS.md")
        
        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_path.write_text(content, encoding='utf-8')
        
        # è¿”å›ç»“æ„åŒ–æ•°æ®ï¼ŒåŒ…å«å®Œæ•´è·¯å¾„ä»¥ä¾¿å‰ç«¯å¿«é€Ÿè®¿é—®
        return json.dumps({
            'action': 'file_created',
            'message': f'å·²æˆåŠŸå†™å…¥ {len(content)} å­—èŠ‚',
            'fileName': file_path.name,
            'filePath': str(file_path.resolve()),
            'fileSize': len(content),
        }, ensure_ascii=False)
    
    def _tool_open_in_explorer(self, args: dict) -> str:
        """åœ¨æ–‡ä»¶ç®¡ç†å™¨ä¸­æ‰“å¼€æŒ‡å®šè·¯å¾„å¹¶é«˜äº®æ–‡ä»¶"""
        path = args.get('path', '')
        if not path:
            raise ValueError("è·¯å¾„å‚æ•°ä¸èƒ½ä¸ºç©º")
        
        file_path = Path(path)
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        import platform
        import subprocess
        system = platform.system()
        
        try:
            if system == 'Windows':
                # Windows: ä½¿ç”¨ explorer /select é«˜äº®æ–‡ä»¶
                subprocess.run(['explorer', '/select,', str(file_path.resolve())], check=False)
            elif system == 'Darwin':  # macOS
                subprocess.run(['open', '-R', str(file_path.resolve())], check=True)
            else:  # Linux
                # æ‰“å¼€çˆ¶ç›®å½•
                subprocess.run(['xdg-open', str(file_path.parent.resolve())], check=True)
            
            return f"å·²åœ¨æ–‡ä»¶ç®¡ç†å™¨ä¸­æ‰“å¼€: {file_path.name}"
        except Exception as e:
            raise RuntimeError(f"æ— æ³•æ‰“å¼€æ–‡ä»¶ç®¡ç†å™¨: {str(e)}")
    
    def _check_nexus_duplication(self, new_content: str) -> str | None:
        """æ£€æŸ¥æ–°å»ºçš„ Nexus æ˜¯å¦ä¸ç°å­˜ Nexus é‡å¤ï¼Œè¿”å›é‡å¤çš„ Nexus ID"""
        # 1. æå–æ–° Nexus çš„ frontmatter
        match = re.match(r'^---\s*\n(.*?)\n---\s*\n', new_content, re.DOTALL)
        if not match:
            return None
        
        new_meta = {}
        if HAS_YAML:
            try:
                new_meta = yaml.safe_load(match.group(1)) or {}
            except Exception:
                pass
        else:
            for line in match.group(1).split('\n'):
                m = re.match(r'^(\w+)\s*:\s*(.+)$', line.strip())
                if m:
                    new_meta[m.group(1)] = m.group(2).strip()
        
        new_name = str(new_meta.get('name', ''))
        new_desc = str(new_meta.get('description', ''))
        if not new_name and not new_desc:
            return None
        
        new_text = f"{new_name} {new_desc}"
        
        # 2. éå†ç°æœ‰ Nexus è¿›è¡Œå¯¹æ¯”
        nexuses_dir = self.clawd_path / 'nexuses'
        if not nexuses_dir.exists():
            return None
        
        best_match = None
        highest_score = 0.0
        
        for nexus_md in nexuses_dir.rglob('NEXUS.md'):
            existing_meta = parse_nexus_frontmatter(nexus_md)
            ext_name = str(existing_meta.get('name', ''))
            ext_desc = str(existing_meta.get('description', ''))
            
            ext_text = f"{ext_name} {ext_desc}"
            score = calculate_text_similarity(new_text, ext_text)
            
            if score > highest_score:
                highest_score = score
                best_match = nexus_md.parent.name
        
        # é˜ˆå€¼ï¼šè¶…è¿‡ 55% çš„ç‰¹å¾é‡åˆå³åˆ¤å®šä¸ºé‡å¤
        if highest_score >= 0.55:
            return best_match
        
        return None
    
    def _tool_append_file(self, args: dict) -> str:
        """è¿½åŠ å†…å®¹åˆ°æ–‡ä»¶"""
        path = args.get('path', '')
        content = args.get('content', '')
        
        file_path = self._resolve_path(path)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(content)
        
        return f"Appended {len(content)} bytes to {file_path.name}"
    
    def _tool_list_dir(self, args: dict) -> str:
        """åˆ—å‡ºç›®å½•å†…å®¹"""
        path = args.get('path', '.')
        dir_path = self._resolve_path(path)
        
        if not dir_path.exists():
            raise FileNotFoundError(f"Directory not found: {path}")
        if not dir_path.is_dir():
            raise ValueError(f"Not a directory: {path}")
        
        items = []
        for item in sorted(dir_path.iterdir()):
            item_type = 'dir' if item.is_dir() else 'file'
            size = item.stat().st_size if item.is_file() else 0
            items.append({
                'name': item.name,
                'type': item_type,
                'size': size
            })
        
        return json.dumps(items, ensure_ascii=False)
    
    def _tool_run_cmd(self, args: dict) -> str:
        """æ‰§è¡Œ Shell å‘½ä»¤ (âš ï¸ é«˜å±æ“ä½œ)"""
        command = args.get('command', '')
        cwd = args.get('cwd', str(self.clawd_path))
        timeout = min(args.get('timeout', 60), 300)  # æœ€å¤§ 5 åˆ†é’Ÿ
        
        if not command:
            raise ValueError("Command cannot be empty")
        
        # å®‰å…¨æ£€æŸ¥
        cmd_lower = command.lower()
        for dangerous in DANGEROUS_COMMANDS:
            if dangerous in cmd_lower:
                raise PermissionError(f"Dangerous command blocked: {command}")
        
        try:
            process = subprocess.run(
                command,
                shell=True,
                cwd=cwd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            stdout = process.stdout[:MAX_OUTPUT_SIZE] if process.stdout else ''
            stderr = process.stderr[:MAX_OUTPUT_SIZE] if process.stderr else ''
            
            result_parts = []
            if stdout:
                result_parts.append(f"STDOUT:\n{stdout}")
            if stderr:
                result_parts.append(f"STDERR:\n{stderr}")
            
            rc = process.returncode
            if rc == 0:
                result_parts.append(f"Exit Code: 0 (æˆåŠŸ)")
            else:
                # æä¾›å¸¸è§ exit code çš„å¯è¯»è§£é‡Š
                code_hints = {
                    1: "é€šç”¨é”™è¯¯",
                    2: "å‚æ•°é”™è¯¯æˆ–å‘½ä»¤è¯¯ç”¨",
                    3: "URL æ ¼å¼é”™è¯¯ (curl)",
                    6: "æ— æ³•è§£æä¸»æœºå (DNS å¤±è´¥)",
                    7: "æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨",
                    28: "æ“ä½œè¶…æ—¶",
                    35: "SSL/TLS è¿æ¥é”™è¯¯",
                    56: "ç½‘ç»œæ•°æ®æ¥æ”¶å¤±è´¥",
                    60: "SSL è¯ä¹¦éªŒè¯å¤±è´¥",
                    127: "å‘½ä»¤æœªæ‰¾åˆ°",
                    128: "æ— æ•ˆçš„é€€å‡ºå‚æ•°",
                }
                hint = code_hints.get(rc, "æœªçŸ¥é”™è¯¯")
                result_parts.append(f"Exit Code: {rc} ({hint})")
                # å½“æ²¡æœ‰ä»»ä½•è¾“å‡ºæ—¶ï¼Œè¡¥å……æç¤ºå¸®åŠ© LLM ç†è§£é”™è¯¯
                if not stdout and not stderr:
                    result_parts.append(f"æ³¨æ„: å‘½ä»¤ '{command[:80]}' æ‰§è¡Œå¤±è´¥ä¸”æ— è¾“å‡ºã€‚å»ºè®®æ¢ç”¨å…¶ä»–å·¥å…·æˆ–æ–¹å¼å®Œæˆä»»åŠ¡ã€‚")
            
            return '\n'.join(result_parts)
        
        except subprocess.TimeoutExpired:
            return f"Command timed out after {timeout}s"
    
    def _tool_weather(self, args: dict) -> str:
        """æŸ¥è¯¢å¤©æ°” (åŸºäº OpenClaw weather skill)"""
        import urllib.request
        import urllib.parse
        
        location = args.get('location', args.get('city', ''))
        if not location:
            raise ValueError("Location/city is required")
        
        # ä½¿ç”¨ wttr.in API (æ— éœ€ API Key)
        encoded_location = urllib.parse.quote(location)
        
        try:
            # è·å–è¯¦ç»†å¤©æ°”ä¿¡æ¯
            url = f"https://wttr.in/{encoded_location}?format=j1"
            req = urllib.request.Request(url, headers={'User-Agent': 'curl/7.68.0'})
            
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
            
            current = data.get('current_condition', [{}])[0]
            area = data.get('nearest_area', [{}])[0]
            
            # æ ¼å¼åŒ–è¾“å‡º
            city_name = area.get('areaName', [{}])[0].get('value', location)
            country = area.get('country', [{}])[0].get('value', '')
            
            result = f"""å¤©æ°”æŸ¥è¯¢ç»“æœ - {city_name}, {country}

å½“å‰æ¸©åº¦: {current.get('temp_C', 'N/A')}Â°C (ä½“æ„Ÿ: {current.get('FeelsLikeC', 'N/A')}Â°C)
å¤©æ°”çŠ¶å†µ: {current.get('weatherDesc', [{}])[0].get('value', 'N/A')}
æ¹¿åº¦: {current.get('humidity', 'N/A')}%
é£é€Ÿ: {current.get('windspeedKmph', 'N/A')} km/h ({current.get('winddir16Point', '')})
èƒ½è§åº¦: {current.get('visibility', 'N/A')} km
ç´«å¤–çº¿æŒ‡æ•°: {current.get('uvIndex', 'N/A')}
"""
            return result
            
        except Exception as e:
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•æ ¼å¼
            try:
                simple_url = f"https://wttr.in/{encoded_location}?format=%l:+%c+%t+(%f)+%h+%w"
                req = urllib.request.Request(simple_url, headers={'User-Agent': 'curl/7.68.0'})
                with urllib.request.urlopen(req, timeout=10) as response:
                    return response.read().decode('utf-8')
            except:
                return f"æ— æ³•æŸ¥è¯¢ {location} çš„å¤©æ°”: {str(e)}"
    
    def _tool_web_search(self, args: dict) -> str:
        """ç½‘é¡µæœç´¢ (ä½¿ç”¨ DuckDuckGo HTML)"""
        import urllib.request
        import urllib.parse
        import re
        
        query = args.get('query', args.get('q', ''))
        if not query:
            raise ValueError("Search query is required")
        
        encoded_query = urllib.parse.quote(query)
        
        try:
            # ä½¿ç”¨ DuckDuckGo HTML ç‰ˆæœ¬
            url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
            req = urllib.request.Request(url, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            with urllib.request.urlopen(req, timeout=15) as response:
                html = response.read().decode('utf-8')
            
            # æå–æœç´¢ç»“æœ
            results = []
            # åŒ¹é…ç»“æœé“¾æ¥å’Œæ ‡é¢˜
            pattern = r'<a[^>]+class="result__a"[^>]*href="([^"]*)"[^>]*>([^<]*)</a>'
            matches = re.findall(pattern, html)
            
            for i, (link, title) in enumerate(matches[:5]):  # å–å‰5ä¸ªç»“æœ
                # æ¸…ç† DuckDuckGo é‡å®šå‘é“¾æ¥
                if 'uddg=' in link:
                    actual_link = urllib.parse.unquote(link.split('uddg=')[-1].split('&')[0])
                else:
                    actual_link = link
                results.append(f"{i+1}. {title.strip()}\n   {actual_link}")
            
            if results:
                return f"æœç´¢ '{query}' çš„ç»“æœ:\n\n" + "\n\n".join(results)
            else:
                return f"æœªæ‰¾åˆ° '{query}' çš„ç›¸å…³ç»“æœ"
                
        except Exception as e:
            return f"æœç´¢å¤±è´¥: {str(e)}"
    
    def _tool_web_fetch(self, args: dict) -> str:
        """è·å–ç½‘é¡µå†…å®¹ (ç®€åŒ–ç‰ˆï¼Œæå–ä¸»è¦æ–‡æœ¬)"""
        import urllib.request
        import urllib.parse
        import re
        from html.parser import HTMLParser
        
        url = args.get('url', '')
        if not url:
            raise ValueError("URL is required")
        
        # ç¡®ä¿ URL æœ‰åè®®
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        try:
            req = urllib.request.Request(url, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            })
            
            with urllib.request.urlopen(req, timeout=15) as response:
                # æ£€æŸ¥å†…å®¹ç±»å‹
                content_type = response.headers.get('Content-Type', '')
                if 'text/html' not in content_type and 'text/plain' not in content_type:
                    return f"æ— æ³•è¯»å–æ­¤ç±»å‹çš„å†…å®¹: {content_type}"
                
                html = response.read().decode('utf-8', errors='ignore')
            
            # ç®€å•çš„ HTML æ–‡æœ¬æå–
            # ç§»é™¤ script å’Œ style æ ‡ç­¾
            html = re.sub(r'<script[^>]*>[\s\S]*?</script>', '', html, flags=re.IGNORECASE)
            html = re.sub(r'<style[^>]*>[\s\S]*?</style>', '', html, flags=re.IGNORECASE)
            html = re.sub(r'<head[^>]*>[\s\S]*?</head>', '', html, flags=re.IGNORECASE)
            
            # æå– title
            title_match = re.search(r'<title[^>]*>([^<]*)</title>', html, re.IGNORECASE)
            title = title_match.group(1).strip() if title_match else ''
            
            # ç§»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
            text = re.sub(r'<[^>]+>', ' ', html)
            # æ¸…ç†å¤šä½™ç©ºç™½
            text = re.sub(r'\s+', ' ', text).strip()
            # é™åˆ¶é•¿åº¦
            text = text[:4000]
            
            result = f"URL: {url}\n"
            if title:
                result += f"æ ‡é¢˜: {title}\n"
            result += f"\nå†…å®¹æ‘˜è¦:\n{text}"
            
            return result
            
        except urllib.error.HTTPError as e:
            return f"HTTP é”™è¯¯ {e.code}: {e.reason}"
        except urllib.error.URLError as e:
            return f"æ— æ³•è®¿é—® URL: {e.reason}"
        except Exception as e:
            return f"è·å–ç½‘é¡µå¤±è´¥: {str(e)}"
    
    def _tool_save_memory(self, args: dict) -> str:
        """ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶"""
        key = args.get('key', '')
        content = args.get('content', '')
        memory_type = args.get('type', 'general')
        
        if not key or not content:
            raise ValueError("key å’Œ content å‚æ•°å¿…å¡«")
        
        # è®°å¿†å­˜å‚¨åœ¨ memory ç›®å½•ä¸‹
        memory_dir = self.clawd_path / 'memory'
        memory_dir.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰æ—¥æœŸç»„ç»‡è®°å¿†æ–‡ä»¶
        today = datetime.now().strftime('%Y-%m-%d')
        memory_file = memory_dir / f'{today}.md'
        
        # æ ¼å¼åŒ–è®°å¿†æ¡ç›®
        timestamp = datetime.now().strftime('%H:%M:%S')
        entry = f"\n## [{timestamp}] {key}\n- **ç±»å‹**: {memory_type}\n- **å†…å®¹**: {content}\n"
        
        # è¿½åŠ åˆ°è®°å¿†æ–‡ä»¶
        with open(memory_file, 'a', encoding='utf-8') as f:
            f.write(entry)
        
        return f"è®°å¿†å·²ä¿å­˜: {key} (ç±»å‹: {memory_type})"
    
    def _tool_search_memory(self, args: dict) -> str:
        """æ£€ç´¢å†å²è®°å¿†"""
        query = args.get('query', '')
        
        if not query:
            raise ValueError("query å‚æ•°å¿…å¡«")
        
        memory_dir = self.clawd_path / 'memory'
        if not memory_dir.exists():
            return "è®°å¿†åº“ä¸ºç©ºï¼Œæš‚æ— å†å²è®°å¿†ã€‚"
        
        results = []
        query_lower = query.lower()
        
        # éå†æ‰€æœ‰è®°å¿†æ–‡ä»¶
        for memory_file in sorted(memory_dir.glob('*.md'), reverse=True)[:7]:  # æœ€è¿‘7å¤©
            try:
                content = memory_file.read_text(encoding='utf-8')
                
                # æŒ‰æ¡ç›®åˆ†å‰²
                entries = content.split('\n## ')
                for entry in entries:
                    if query_lower in entry.lower():
                        # æå–æ—¥æœŸå’Œå†…å®¹
                        date = memory_file.stem
                        results.append(f"[{date}] {entry.strip()[:200]}")
                        
                        if len(results) >= 5:  # æœ€å¤šè¿”å›5æ¡
                            break
            except Exception:
                continue
            
            if len(results) >= 5:
                break
        
        if results:
            return f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†:\n\n" + "\n\n---\n\n".join(results)
        else:
            return f"æœªæ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„è®°å¿†ã€‚"
    
    def _tool_nexus_bind_skill(self, args: dict) -> str:
        """ä¸º Nexus ç»‘å®šæ–°æŠ€èƒ½"""
        nexus_id = args.get('nexusId', '')
        skill_id = args.get('skillId', '')
        if not nexus_id or not skill_id:
            raise ValueError('Missing nexusId or skillId')

        nexus_md = self.clawd_path / 'nexuses' / nexus_id / 'NEXUS.md'
        if not nexus_md.exists():
            raise ValueError(f"Nexus '{nexus_id}' not found")

        # éªŒè¯æŠ€èƒ½å­˜åœ¨ (skills/ ç›®å½•ä¸­æœ‰å¯¹åº”ç›®å½•)
        skill_dir = self.clawd_path / 'skills' / skill_id
        if not skill_dir.exists():
            raise ValueError(f"Skill '{skill_id}' not found in skills/")

        frontmatter = parse_nexus_frontmatter(nexus_md)
        deps = list(frontmatter.get('skill_dependencies', []))

        if skill_id in deps:
            return f"Skill '{skill_id}' already bound to Nexus '{nexus_id}'"

        deps.append(skill_id)
        update_nexus_frontmatter(nexus_md, {'skill_dependencies': deps})
        return f"Skill '{skill_id}' bound to Nexus '{nexus_id}'. Dependencies: {deps}"

    def _tool_nexus_unbind_skill(self, args: dict) -> str:
        """ä» Nexus è§£ç»‘æŠ€èƒ½"""
        nexus_id = args.get('nexusId', '')
        skill_id = args.get('skillId', '')
        if not nexus_id or not skill_id:
            raise ValueError('Missing nexusId or skillId')

        nexus_md = self.clawd_path / 'nexuses' / nexus_id / 'NEXUS.md'
        if not nexus_md.exists():
            raise ValueError(f"Nexus '{nexus_id}' not found")

        frontmatter = parse_nexus_frontmatter(nexus_md)
        deps = list(frontmatter.get('skill_dependencies', []))

        if skill_id not in deps:
            return f"Skill '{skill_id}' not bound to Nexus '{nexus_id}'"

        if len(deps) <= 1:
            return f"Cannot remove last skill from Nexus '{nexus_id}'. At least 1 skill required."

        deps.remove(skill_id)
        update_nexus_frontmatter(nexus_md, {'skill_dependencies': deps})
        return f"Skill '{skill_id}' unbound from Nexus '{nexus_id}'. Remaining: {deps}"

    def _tool_generate_skill(self, args: dict) -> str:
        """åŠ¨æ€ç”Ÿæˆ Python SKILL å¹¶ä¿å­˜
        
        å½“é‡åˆ°æ— æ³•å®Œæˆçš„ä»»åŠ¡æ—¶ï¼ŒAgent å¯ä»¥è°ƒç”¨æ­¤å·¥å…·ç”Ÿæˆæ–°çš„ Python æŠ€èƒ½æ¥è§£å†³é—®é¢˜ã€‚
        ç”Ÿæˆçš„æŠ€èƒ½ä¼šä¿å­˜åˆ° skills/ ç›®å½•ï¼ˆæˆ– nexuses/{nexusId}/ ç›®å½•ï¼‰å¹¶è‡ªåŠ¨çƒ­åŠ è½½ã€‚
        
        å‚æ•°:
        - name: æŠ€èƒ½åç§° (kebab-case, å¦‚ "pdf-merger")
        - description: æŠ€èƒ½æè¿°
        - pythonCode: Python å®ç°ä»£ç  (å¿…é¡»åŒ…å« main() å‡½æ•°)
        - nexusId: å¯é€‰ï¼Œå¦‚æœæŒ‡å®šåˆ™ä¿å­˜åˆ°å¯¹åº” Nexus ç›®å½•
        - triggers: å¯é€‰ï¼Œè§¦å‘å…³é”®è¯åˆ—è¡¨
        """
        name = args.get('name', '')
        description = args.get('description', '')
        python_code = args.get('pythonCode', '')
        nexus_id = args.get('nexusId', '')
        triggers = args.get('triggers', [])
        
        if not name or not description or not python_code:
            raise ValueError("Missing required parameters: name, description, pythonCode")
        
        # è§„èŒƒåŒ–æŠ€èƒ½åç§° (kebab-case)
        safe_name = re.sub(r'[^\w-]', '-', name.lower()).strip('-')
        safe_name = re.sub(r'-+', '-', safe_name)
        
        if not safe_name:
            raise ValueError("Invalid skill name")
        
        # éªŒè¯ Python ä»£ç åŒ…å« main() å‡½æ•°
        if 'def main(' not in python_code and 'async def main(' not in python_code:
            raise ValueError("Python code must contain a main() function")
        
        # ç¡®å®šä¿å­˜è·¯å¾„
        if nexus_id:
            # ä¿å­˜åˆ° Nexus ä¸“å±ç›®å½•
            skill_dir = self.clawd_path / 'nexuses' / nexus_id / 'skills' / safe_name
        else:
            # ä¿å­˜åˆ°å…¨å±€ skills ç›®å½•
            skill_dir = self.clawd_path / 'skills' / safe_name
        
        skill_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆ SKILL.md
        trigger_list = '\n'.join(f'- {t}' for t in triggers) if triggers else f'- {safe_name}'
        skill_md_content = f'''---
name: {safe_name}
description: {description}
version: "1.0.0"
author: auto-generated
triggers:
{trigger_list}
---

# {name}

{description}

## ä½¿ç”¨æ–¹æ³•

æ­¤æŠ€èƒ½ç”± DD-OS Agent è‡ªåŠ¨ç”Ÿæˆï¼Œç”¨äºè§£å†³ç‰¹å®šä»»åŠ¡ã€‚

### æ‰§è¡Œ

```bash
python {safe_name}.py
```

### å‚æ•°

è¯·å‚è€ƒ Python ä»£ç ä¸­çš„ `main()` å‡½æ•°ç­¾åã€‚

## å®ç°

å‚è§ `{safe_name}.py`
'''
        
        # å†™å…¥æ–‡ä»¶
        skill_md_path = skill_dir / 'SKILL.md'
        skill_md_path.write_text(skill_md_content, encoding='utf-8')
        
        python_file_path = skill_dir / f'{safe_name}.py'
        python_file_path.write_text(python_code, encoding='utf-8')
        
        # çƒ­åŠ è½½: é‡æ–°æ³¨å†Œå·¥å…·
        try:
            tool_registry.refresh_skills()
            loaded_msg = "å¹¶å·²çƒ­åŠ è½½åˆ°å·¥å…·åˆ—è¡¨"
        except Exception as e:
            loaded_msg = f"ä½†çƒ­åŠ è½½å¤±è´¥: {e}"
        
        return json.dumps({
            'action': 'skill_created',
            'message': f'æŠ€èƒ½ "{safe_name}" å·²æˆåŠŸåˆ›å»º{loaded_msg}',
            'skillName': safe_name,
            'skillDir': str(skill_dir),
            'files': [str(skill_md_path), str(python_file_path)],
            'nexusId': nexus_id or None,
        }, ensure_ascii=False)

    # ============================================
    # åŸæœ‰å¤„ç†å™¨ (ä¿æŒå…¼å®¹)
    # ============================================
    
    def handle_index(self):
        html = f"""<!DOCTYPE html>
<html>
<head><title>DD-OS Native Server</title></head>
<body style="font-family: monospace; background: #0f172a; color: #e2e8f0; padding: 30px;">
<h1>DD-OS Native Server v{VERSION}</h1>
<p style="color: #94a3b8;">ç‹¬ç«‹è¿è¡Œçš„æœ¬åœ° AI æ“ä½œç³»ç»Ÿåç«¯</p>
<p>Clawd Path: <code style="color: #22d3ee;">{self.clawd_path}</code></p>

<h2>ğŸ“¡ API Endpoints</h2>
<div style="background: #1e293b; padding: 15px; border-radius: 8px;">
<h3 style="color: #f59e0b;">æ•°æ®è¯»å–</h3>
<ul>
<li><a href="/status" style="color: #60a5fa;">/status</a> - æœåŠ¡çŠ¶æ€</li>
<li><a href="/files" style="color: #60a5fa;">/files</a> - æ–‡ä»¶åˆ—è¡¨</li>
<li><a href="/file/SOUL.md" style="color: #60a5fa;">/file/SOUL.md</a> - è¯»å– SOUL</li>
<li><a href="/skills" style="color: #60a5fa;">/skills</a> - æŠ€èƒ½åˆ—è¡¨</li>
<li><a href="/all" style="color: #60a5fa;">/all</a> - æ‰€æœ‰æ•°æ®</li>
</ul>

<h3 style="color: #10b981;">ğŸ› ï¸ å·¥å…·æ‰§è¡Œ (POST)</h3>
<ul>
<li><code>/api/tools/execute</code> - æ‰§è¡Œå·¥å…·</li>
<li>æ”¯æŒ: readFile, writeFile, listDir, runCmd, appendFile</li>
</ul>
</div>

<h2>ğŸ§ª æµ‹è¯•</h2>
<pre style="background: #1e293b; padding: 15px; border-radius: 8px; overflow-x: auto;">
curl -X POST http://localhost:3001/api/tools/execute \\
  -H "Content-Type: application/json" \\
  -d '{{"name": "listDir", "args": {{"path": "."}}}}'
</pre>
</body>
</html>"""
        
        self.send_response(200)
        self.send_header('Content-Type', 'text/html; charset=utf-8')
        self.send_cors_headers()
        self.end_headers()
        self.wfile.write(html.encode('utf-8'))
    
    def handle_status(self):
        files = list_files(self.clawd_path)
        skills_dir = self.clawd_path / 'skills'
        skill_count = len(list(skills_dir.iterdir())) if skills_dir.exists() else 0
        
        self.send_json({
            'status': 'ok',
            'version': VERSION,
            'mode': 'native',
            'clawdPath': str(self.clawd_path),
            'fileCount': len(files),
            'skillCount': skill_count,
            'tools': [t['name'] for t in self.registry.list_all()],
            'toolCount': len(self.registry.list_all()),
            'timestamp': datetime.now().isoformat()
        })
    
    def handle_files(self):
        files = list_files(self.clawd_path)
        self.send_json(files)
    
    def handle_file(self, filename):
        filepath = self.clawd_path / filename
        if not filepath.exists():
            self.send_error_json(f'File not found: {filename}', 404)
            return
        
        if not filepath.is_file():
            self.send_error_json(f'Not a file: {filename}', 400)
            return
        
        try:
            filepath.resolve().relative_to(self.clawd_path.resolve())
        except ValueError:
            self.send_error_json('Access denied', 403)
            return
        
        try:
            content = filepath.read_text(encoding='utf-8')
            self.send_text(content)
        except Exception as e:
            self.send_error_json(f'Read error: {str(e)}', 500)
    
    def handle_skills(self):
        """GET /skills - é€’å½’æ‰«ææ‰€æœ‰æŠ€èƒ½ (SKILL.md + manifest.json)ï¼Œæ”¯æŒç”¨æˆ·ç›®å½• + é¡¹ç›®ç›®å½•"""
        skills = []
        seen = set()
        seen_ids = set()  # é˜²æ­¢é‡å¤æŠ€èƒ½ (ç”¨æˆ·ç›®å½•ä¼˜å…ˆ)
        
        # è·å–æŠ€èƒ½ç›®å½•åˆ—è¡¨ï¼šç”¨æˆ·ç›®å½•ä¼˜å…ˆï¼Œé¡¹ç›®ç›®å½•ä½œä¸ºåå¤‡
        skills_dirs = []
        user_skills_dir = self.clawd_path / 'skills'
        if user_skills_dir.exists() and user_skills_dir.is_dir():
            skills_dirs.append(('user', user_skills_dir))
        
        project_path = self.project_path or Path(__file__).parent.resolve()
        project_skills_dir = project_path / 'skills'
        if project_skills_dir.exists() and project_skills_dir.is_dir() and project_skills_dir != user_skills_dir:
            skills_dirs.append(('bundled', project_skills_dir))
        
        if not skills_dirs:
            self.send_json([])
            return

        for source, skills_dir in skills_dirs:
            # Phase 1: æ‰«ææœ‰ SKILL.md çš„ç›®å½•
            for skill_md in skills_dir.rglob('SKILL.md'):
                skill_dir = skill_md.parent
                dir_key = str(skill_dir.resolve())
                skill_id = skill_dir.name
                
                if dir_key in seen or skill_id in seen_ids:
                    continue
                seen.add(dir_key)
                seen_ids.add(skill_id)

                frontmatter = parse_skill_frontmatter(skill_md)
                manifest_path = skill_dir / 'manifest.json'

                skill_data = {
                    'id': skill_id,
                    'name': frontmatter.get('name', skill_dir.name),
                    'description': frontmatter.get('description', ''),
                    'location': source,  # 'user' æˆ– 'bundled'
                    'path': str(skill_dir),
                    'status': 'active',
                    'enabled': True,
                    'keywords': frontmatter.get('tags', frontmatter.get('keywords', [])),
                }

                # æ—  frontmatter description æ—¶æå–æ­£æ–‡é¦–æ®µ
                if not skill_data['description']:
                    try:
                        content = skill_md.read_text(encoding='utf-8')
                        for line in content.split('\n'):
                            line = line.strip()
                            if line and not line.startswith('#') and not line.startswith('---'):
                                skill_data['description'] = line[:200]
                                break
                    except Exception:
                        pass

                self._enrich_skill_from_manifest(skill_data, manifest_path, frontmatter)
                skills.append(skill_data)

            # Phase 2: æ‰«ææœ‰ manifest.json ä½†æ²¡æœ‰ SKILL.md çš„ç›®å½•
            for manifest_path in skills_dir.rglob('manifest.json'):
                skill_dir = manifest_path.parent
                dir_key = str(skill_dir.resolve())
                skill_id = skill_dir.name
                
                if dir_key in seen or skill_id in seen_ids:
                    continue
                seen.add(dir_key)
                seen_ids.add(skill_id)

                try:
                    manifest = json.loads(manifest_path.read_text(encoding='utf-8'))
                except Exception:
                    continue

                skill_data = {
                    'id': skill_id,
                    'name': manifest.get('name', skill_dir.name),
                    'description': manifest.get('description', ''),
                    'location': source,
                    'path': str(skill_dir),
                    'status': 'active',
                    'enabled': True,
                    'keywords': manifest.get('keywords', []),
                }

                self._enrich_skill_from_manifest(skill_data, manifest_path, {})
                skills.append(skill_data)

        self.send_json(skills)

    def _enrich_skill_from_manifest(self, skill_data: dict, manifest_path: Path, frontmatter: dict):
        """ä» manifest.json è¡¥å……æŠ€èƒ½å…ƒæ•°æ® (å¤šå·¥å…·æ ¼å¼ + å…³é”®è¯åˆå¹¶)"""
        if manifest_path.exists():
            try:
                manifest = json.loads(manifest_path.read_text(encoding='utf-8'))

                # æ”¯æŒæ–°æ ¼å¼ tools: [...] å’Œæ—§æ ¼å¼ toolName: "..."
                tools_list = manifest.get('tools', [])
                if not tools_list:
                    tools_list = [manifest]

                tool_names = [t.get('toolName') for t in tools_list if t.get('toolName')]
                if tool_names:
                    skill_data['toolNames'] = tool_names
                    skill_data['toolName'] = tool_names[0]
                    skill_data['executable'] = True

                # åˆå¹¶å…³é”®è¯ (manifest ä¼˜å…ˆ)
                manifest_keywords = list(manifest.get('keywords', []))
                for t in tools_list:
                    manifest_keywords.extend(t.get('keywords', []))
                if manifest_keywords:
                    skill_data['keywords'] = list(set(manifest_keywords))

                skill_data['dangerLevel'] = manifest.get('dangerLevel', 'safe')
                skill_data['version'] = manifest.get('version', '1.0.0')
                if manifest.get('description'):
                    skill_data['description'] = manifest['description']

                # åˆå¹¶æ‰€æœ‰ inputs
                all_inputs = {}
                for t in tools_list:
                    all_inputs.update(t.get('inputs', {}))
                if all_inputs:
                    skill_data['inputs'] = all_inputs

            except Exception:
                pass
        else:
            # çº¯ SKILL.md - æŒ‡ä»¤å‹æŠ€èƒ½
            skill_data['toolType'] = 'instruction'
            tool_name = skill_name_to_tool_name(skill_data['name'])
            skill_data['toolName'] = tool_name
            skill_data['toolNames'] = [tool_name]
            if frontmatter.get('inputs'):
                skill_data['inputs'] = frontmatter['inputs']

    # ============================================
    # ğŸŒŒ Nexus ç®¡ç†
    # ============================================

    def handle_nexuses(self):
        """GET /nexuses - æ‰«æ nexuses/ ç›®å½•ï¼Œè¿”å›æ‰€æœ‰ Nexus åˆ—è¡¨"""
        nexuses = []
        nexuses_dir = self.clawd_path / 'nexuses'

        if not nexuses_dir.exists():
            nexuses_dir.mkdir(parents=True, exist_ok=True)
            self.send_json([])
            return

        seen = set()

        for nexus_md in nexuses_dir.rglob('NEXUS.md'):
            nexus_dir = nexus_md.parent
            dir_key = str(nexus_dir.resolve())
            if dir_key in seen:
                continue
            seen.add(dir_key)

            frontmatter = parse_nexus_frontmatter(nexus_md)
            if not frontmatter or not frontmatter.get('name'):
                continue

            sop_content = extract_nexus_body(nexus_md)
            exp_dir = nexus_dir / 'experience'
            xp = count_experience_entries(exp_dir) if exp_dir.exists() else 0

            visual_dna = frontmatter.get('visual_dna', {})

            nexus_data = {
                'id': frontmatter.get('name', nexus_dir.name),
                'name': frontmatter.get('name', nexus_dir.name),
                'description': frontmatter.get('description', ''),
                'archetype': frontmatter.get('archetype', 'REACTOR'),
                'version': frontmatter.get('version', '1.0.0'),
                'skillDependencies': frontmatter.get('skill_dependencies', []),
                'tags': frontmatter.get('tags', []),
                'triggers': frontmatter.get('triggers', []),
                'visualDNA': visual_dna,
                'sopContent': sop_content,
                'xp': xp,
                'location': 'local',
                'path': str(nexus_dir),
                'status': 'active',
                # ç›®æ ‡å‡½æ•°é©±åŠ¨å­—æ®µ (Objective-Driven Execution)
                'objective': frontmatter.get('objective', ''),
                'metrics': frontmatter.get('metrics', []),
                'strategy': frontmatter.get('strategy', ''),
            }
            nexuses.append(nexus_data)

        self.send_json(nexuses)

    def handle_nexuses_health(self):
        """GET /nexuses/health - æ£€æŸ¥ nexuses ç›®å½•çš„é…ç½®å¥åº·çŠ¶å†µ"""
        nexuses_dir = self.clawd_path / 'nexuses'
        issues = []
        suggestions = []
        stats = {
            'valid_nexuses': 0,
            'orphan_files': 0,
            'missing_nexus_md': 0,
            'invalid_frontmatter': 0,
        }

        if not nexuses_dir.exists():
            self.send_json({
                'healthy': True,
                'issues': [],
                'suggestions': ['nexuses ç›®å½•ä¸ºç©ºï¼Œå¯ä»¥å¼€å§‹åˆ›å»º Nexus'],
                'stats': stats
            })
            return

        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„ Nexus ç›®å½•
        valid_dirs = set()
        for nexus_md in nexuses_dir.rglob('NEXUS.md'):
            nexus_dir = nexus_md.parent
            frontmatter = parse_nexus_frontmatter(nexus_md)
            if frontmatter and frontmatter.get('name'):
                valid_dirs.add(str(nexus_dir.resolve()))
                stats['valid_nexuses'] += 1
            else:
                stats['invalid_frontmatter'] += 1
                issues.append({
                    'type': 'invalid_frontmatter',
                    'path': str(nexus_md),
                    'message': f"NEXUS.md ç¼ºå°‘å¿…è¦çš„ 'name' å­—æ®µ",
                })

        # æ£€æŸ¥å­¤ç«‹æ–‡ä»¶ï¼ˆæœ‰ .json ä½†æ²¡æœ‰ NEXUS.mdï¼‰
        for item in nexuses_dir.iterdir():
            if item.is_file() and item.suffix == '.json':
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„ NEXUS.md ç›®å½•
                stem = item.stem.replace('.json', '')
                potential_dir = nexuses_dir / stem
                if not (potential_dir / 'NEXUS.md').exists():
                    stats['orphan_files'] += 1
                    issues.append({
                        'type': 'orphan_json',
                        'path': str(item),
                        'message': f"å‘ç°å­¤ç«‹çš„ JSON æ–‡ä»¶ï¼Œæ²¡æœ‰å¯¹åº”çš„ NEXUS.md",
                        'suggestion': f"åˆ›å»º {stem}/NEXUS.md æˆ–åˆ é™¤æ­¤æ–‡ä»¶",
                    })
                    suggestions.append(
                        f"æ–‡ä»¶ '{item.name}' å¯èƒ½æ˜¯ AI ç”Ÿæˆçš„é…ç½®ï¼Œéœ€è¦è½¬æ¢ä¸º NEXUS.md æ ¼å¼æ‰èƒ½è¢«ç³»ç»Ÿè¯†åˆ«"
                    )

            # æ£€æŸ¥ç›®å½•ä½†æ²¡æœ‰ NEXUS.md
            if item.is_dir() and not (item / 'NEXUS.md').exists():
                # æ£€æŸ¥ç›®å½•å†…æ˜¯å¦æœ‰å…¶ä»–æ–‡ä»¶
                files = list(item.iterdir())
                if files:
                    stats['missing_nexus_md'] += 1
                    issues.append({
                        'type': 'missing_nexus_md',
                        'path': str(item),
                        'message': f"ç›®å½• '{item.name}' ç¼ºå°‘ NEXUS.md æ–‡ä»¶",
                        'files': [f.name for f in files[:5]],
                    })

        healthy = len(issues) == 0
        self.send_json({
            'healthy': healthy,
            'issues': issues,
            'suggestions': suggestions,
            'stats': stats,
            'tip': 'è¿è¡Œ /nexuses æŸ¥çœ‹æ‰€æœ‰æœ‰æ•ˆçš„ Nexus' if healthy else 'è¯·ä¿®å¤ä¸Šè¿°é—®é¢˜åé‡æ–°æ£€æŸ¥',
        })

    def handle_nexus_detail(self, nexus_name: str):
        """GET /nexuses/{name} - è·å–å•ä¸ª Nexus å®Œæ•´ä¿¡æ¯"""
        nexuses_dir = self.clawd_path / 'nexuses'
        nexus_dir = nexuses_dir / nexus_name
        nexus_md = nexus_dir / 'NEXUS.md'

        if not nexus_md.exists():
            self.send_error_json(f"Nexus '{nexus_name}' not found", 404)
            return

        frontmatter = parse_nexus_frontmatter(nexus_md)
        sop_content = extract_nexus_body(nexus_md)
        exp_dir = nexus_dir / 'experience'
        xp = count_experience_entries(exp_dir) if exp_dir.exists() else 0

        # åŠ è½½æœ€è¿‘ç»éªŒæ¡ç›®
        recent_experiences = []
        for exp_file in ['successes.md', 'failures.md']:
            exp_path = exp_dir / exp_file
            if not exp_path.exists():
                continue
            try:
                content = exp_path.read_text(encoding='utf-8')
                outcome = 'success' if 'success' in exp_file else 'failure'
                entries = content.split('\n### ')
                for entry in entries[1:]:  # skip header
                    entry = entry.strip()
                    if not entry:
                        continue
                    lines = entry.split('\n')
                    title = lines[0].strip() if lines else ''
                    recent_experiences.append({
                        'title': title,
                        'outcome': outcome,
                        'content': '\n'.join(lines[1:]).strip(),
                    })
            except Exception:
                pass

        # æŒ‰æ—¶é—´å€’åºï¼ˆæ ‡é¢˜é€šå¸¸åŒ…å«æ—¥æœŸï¼‰
        recent_experiences = recent_experiences[-10:][::-1]

        visual_dna = frontmatter.get('visual_dna', {})

        response = {
            'id': frontmatter.get('name', nexus_name),
            'name': frontmatter.get('name', nexus_name),
            'description': frontmatter.get('description', ''),
            'archetype': frontmatter.get('archetype', 'REACTOR'),
            'version': frontmatter.get('version', '1.0.0'),
            'skillDependencies': frontmatter.get('skill_dependencies', []),
            'tags': frontmatter.get('tags', []),
            'triggers': frontmatter.get('triggers', []),
            'visualDNA': visual_dna,
            'sopContent': sop_content,
            'xp': xp,
            'recentExperiences': recent_experiences,
            'location': 'local',
            'path': str(nexus_dir),
            'status': 'active',
            # ç›®æ ‡å‡½æ•°é©±åŠ¨å­—æ®µ (Objective-Driven Execution)
            'objective': frontmatter.get('objective', ''),
            'metrics': frontmatter.get('metrics', []),
            'strategy': frontmatter.get('strategy', ''),
        }
        self.send_json(response)

    def handle_nexus_update_skills(self, nexus_name: str, data: dict):
        """POST /nexuses/{name}/skills - æ›´æ–° Nexus æŠ€èƒ½ä¾èµ–"""
        action = data.get('action', '')  # 'add' or 'remove'
        skill_id = data.get('skillId', '')

        if action not in ('add', 'remove') or not skill_id:
            self.send_error_json('Invalid: need action (add/remove) and skillId', 400)
            return

        nexus_dir = self.clawd_path / 'nexuses' / nexus_name
        nexus_md = nexus_dir / 'NEXUS.md'
        if not nexus_md.exists():
            self.send_error_json(f"Nexus '{nexus_name}' not found", 404)
            return

        frontmatter = parse_nexus_frontmatter(nexus_md)
        deps = list(frontmatter.get('skill_dependencies', []))

        if action == 'add':
            if skill_id not in deps:
                deps.append(skill_id)
        elif action == 'remove':
            if len(deps) <= 1:
                self.send_error_json('Cannot remove last skill dependency', 400)
                return
            if skill_id in deps:
                deps.remove(skill_id)

        update_nexus_frontmatter(nexus_md, {'skill_dependencies': deps})

        self.send_json({
            'status': 'ok',
            'nexusId': nexus_name,
            'skillDependencies': deps,
        })

    def handle_nexus_update_meta(self, nexus_name: str, data: dict):
        """POST /nexuses/{name}/meta - æ›´æ–° Nexus å…ƒæ•°æ®(åç§°ç­‰)"""
        nexus_dir = self.clawd_path / 'nexuses' / nexus_name
        nexus_md = nexus_dir / 'NEXUS.md'
        
        if not nexus_md.exists():
            self.send_error_json(f"Nexus '{nexus_name}' not found", 404)
            return

        new_name = data.get('name', '').strip()
        if not new_name:
            self.send_error_json('Invalid: name is required', 400)
            return
            
        update_nexus_frontmatter(nexus_md, {'name': new_name})

        self.send_json({
            'status': 'ok',
            'nexusId': nexus_name,
            'name': new_name
        })

    def handle_add_experience(self, nexus_name: str, data: dict):
        """POST /nexuses/{name}/experience - ä¸º Nexus æ·»åŠ ç»éªŒè®°å½•"""
        nexuses_dir = self.clawd_path / 'nexuses'
        nexus_dir = nexuses_dir / nexus_name

        if not nexus_dir.exists():
            self.send_error_json(f"Nexus '{nexus_name}' not found", 404)
            return

        task = data.get('task', '')
        tools_used = data.get('tools_used', [])
        outcome = data.get('outcome', 'success')
        key_insight = data.get('key_insight', '')

        if not task:
            self.send_error_json('Missing required field: task', 400)
            return

        # ç¡®ä¿ experience ç›®å½•å­˜åœ¨
        exp_dir = nexus_dir / 'experience'
        exp_dir.mkdir(parents=True, exist_ok=True)

        # æ„å»º Markdown æ¡ç›®
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y-%m-%d')
        tool_seq = ' â†’ '.join(tools_used) if tools_used else 'N/A'

        entry = f"\n### [{timestamp}] {task[:80]}\n"
        entry += f"- **Tools**: {tool_seq}\n"
        if key_insight:
            entry += f"- **Insight**: {key_insight}\n"
        entry += "---\n"

        # è¿½åŠ åˆ°å¯¹åº”æ–‡ä»¶
        target_file = exp_dir / ('successes.md' if outcome == 'success' else 'failures.md')
        try:
            with target_file.open('a', encoding='utf-8') as f:
                f.write(entry)
            self.send_json({'status': 'ok', 'outcome': outcome})
        except Exception as e:
            self.send_error_json(f'Failed to write experience: {str(e)}', 500)

    def handle_tools_list(self):
        """GET /tools - åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·"""
        self.send_json(self.registry.list_all())

    def handle_tools_reload(self, data=None):
        """POST /tools/reload - çƒ­é‡è½½æ’ä»¶å·¥å…·"""
        self.registry.plugin_tools.clear()
        self.registry.instruction_tools.clear()
        self.registry.scan_plugins()
        tools = self.registry.list_all()
        self.send_json({
            'status': 'ok',
            'message': f'Reloaded. {len(tools)} tools registered.',
            'tools': tools,
        })

    # ============================================
    # ğŸ”Œ MCP æœåŠ¡å™¨ç®¡ç†
    # ============================================

    def handle_mcp_servers_list(self):
        """GET /mcp/servers - åˆ—å‡º MCP æœåŠ¡å™¨çŠ¶æ€"""
        if not self.registry.mcp_manager:
            self.send_json({
                'status': 'ok',
                'enabled': False,
                'servers': {},
                'message': 'MCP support not initialized'
            })
            return

        status = self.registry.mcp_manager.get_server_status()
        mcp_tools = [t for t in self.registry.list_all() if t.get('type') == 'mcp']

        self.send_json({
            'status': 'ok',
            'enabled': True,
            'servers': status,
            'toolCount': len(mcp_tools),
            'tools': mcp_tools,
        })

    def handle_mcp_reload(self, data=None):
        """POST /mcp/reload - é‡æ–°åŠ è½½ MCP æœåŠ¡å™¨"""
        if not HAS_MCP:
            self.send_json({
                'status': 'error',
                'message': 'MCP support not available'
            }, 400)
            return

        # æ¸…ç†ç°æœ‰ MCP å·¥å…·
        self.registry.mcp_tools.clear()
        if self.registry.mcp_manager:
            self.registry.mcp_manager.shutdown_all()

        # é‡æ–°æ‰«æ
        self.registry.scan_mcp_servers()

        mcp_tools = [t for t in self.registry.list_all() if t.get('type') == 'mcp']
        self.send_json({
            'status': 'ok',
            'message': f'MCP reloaded. {len(mcp_tools)} tool(s) registered.',
            'tools': mcp_tools,
        })

    def handle_mcp_reconnect(self, server_name: str):
        """POST /mcp/servers/{name}/reconnect - é‡è¿ MCP æœåŠ¡å™¨"""
        if not self.registry.mcp_manager:
            self.send_json({
                'status': 'error',
                'message': 'MCP support not initialized'
            }, 400)
            return

        success = self.registry.mcp_manager.reconnect_server(server_name)

        if success:
            # æ›´æ–°å·¥å…·æ³¨å†Œ
            self.registry.mcp_tools.clear()
            for tool_info in self.registry.mcp_manager.get_all_tools():
                tool_name = tool_info['name']
                if tool_name not in self.registry.builtin_tools and tool_name not in self.registry.plugin_tools:
                    self.registry.mcp_tools[tool_name] = {
                        'name': tool_name,
                        'server': tool_info.get('server', ''),
                        'description': tool_info.get('description', ''),
                        'inputs': tool_info.get('inputs', {}),
                        'dangerLevel': 'safe',
                        'version': '1.0.0',
                    }

            self.send_json({
                'status': 'ok',
                'message': f'Server {server_name} reconnected',
                'server': server_name,
            })
        else:
            self.send_json({
                'status': 'error',
                'message': f'Failed to reconnect server: {server_name}'
            }, 500)

    # ============================================
    # ğŸ” Registry åœ¨çº¿æœç´¢ (TF-IDF, æ—  LLM)
    # ============================================

    def handle_registry_skills_search(self, query: dict):
        """GET /api/registry/skills?q={query} - æœç´¢å¯å®‰è£…çš„æŠ€èƒ½"""
        q = query.get('q', [''])[0].strip().lower()
        
        # è¯»å– registry æ–‡ä»¶
        registry_path = self.clawd_path / 'registry' / 'skills.json'
        if not registry_path.exists():
            self.send_json({'status': 'ok', 'results': [], 'message': 'Registry not found'})
            return
        
        try:
            registry = json.loads(registry_path.read_text(encoding='utf-8'))
            skills = registry.get('skills', [])
        except Exception as e:
            self.send_json({'status': 'error', 'message': f'Failed to read registry: {e}'}, 500)
            return
        
        # å¦‚æœæ²¡æœ‰æŸ¥è¯¢è¯ï¼Œè¿”å›æ‰€æœ‰
        if not q:
            self.send_json({
                'status': 'ok',
                'results': skills[:20],
                'total': len(skills)
            })
            return
        
        # TF-IDF é£æ ¼çš„å…³é”®è¯åŒ¹é…
        tokens = self._tokenize(q)
        scored_results = []
        
        for skill in skills:
            score = self._compute_skill_score(skill, tokens)
            if score > 0:
                scored_results.append({**skill, 'score': score})
        
        # æŒ‰åˆ†æ•°æ’åº
        scored_results.sort(key=lambda x: x['score'], reverse=True)
        
        self.send_json({
            'status': 'ok',
            'results': scored_results[:10],
            'total': len(scored_results),
            'query': q
        })

    def handle_registry_mcp_search(self, query: dict):
        """GET /api/registry/mcp?q={query} - æœç´¢å¯å®‰è£…çš„ MCP æœåŠ¡å™¨"""
        q = query.get('q', [''])[0].strip().lower()
        
        # è¯»å– registry æ–‡ä»¶
        registry_path = self.clawd_path / 'registry' / 'mcp-servers.json'
        if not registry_path.exists():
            self.send_json({'status': 'ok', 'results': [], 'message': 'Registry not found'})
            return
        
        try:
            registry = json.loads(registry_path.read_text(encoding='utf-8'))
            servers = registry.get('servers', [])
        except Exception as e:
            self.send_json({'status': 'error', 'message': f'Failed to read registry: {e}'}, 500)
            return
        
        # å¦‚æœæ²¡æœ‰æŸ¥è¯¢è¯ï¼Œè¿”å›æ‰€æœ‰
        if not q:
            self.send_json({
                'status': 'ok',
                'results': servers[:20],
                'total': len(servers)
            })
            return
        
        # TF-IDF é£æ ¼çš„å…³é”®è¯åŒ¹é…
        tokens = self._tokenize(q)
        scored_results = []
        
        for server in servers:
            score = self._compute_mcp_score(server, tokens)
            if score > 0:
                scored_results.append({**server, 'score': score})
        
        # æŒ‰åˆ†æ•°æ’åº
        scored_results.sort(key=lambda x: x['score'], reverse=True)
        
        self.send_json({
            'status': 'ok',
            'results': scored_results[:10],
            'total': len(scored_results),
            'query': q
        })

    def _tokenize(self, text: str) -> list:
        """åˆ†è¯ï¼šæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹æ‹†åˆ†"""
        import re
        tokens = re.split(r'[\s,ï¼Œ.ã€‚!ï¼?ï¼Ÿã€;ï¼›:ï¼š\-â€”]+', text.lower())
        return [t for t in tokens if t and len(t) >= 1]

    def _compute_skill_score(self, skill: dict, tokens: list) -> float:
        """è®¡ç®—æŠ€èƒ½çš„åŒ¹é…åˆ†æ•° (TF-IDF ç®€åŒ–ç‰ˆ)"""
        score = 0.0
        name = skill.get('name', '').lower()
        desc = skill.get('description', '').lower()
        keywords = [k.lower() for k in skill.get('keywords', [])]
        full_text = f"{name} {desc} {' '.join(keywords)}"
        
        for token in tokens:
            # è¯é¢‘ (TF)
            tf = full_text.count(token)
            # é•¿è¯æƒé‡æ›´é«˜ (ç®€åŒ– IDF)
            idf = 1.5 if len(token) > 3 else 1.0
            score += tf * idf
            
            # ç²¾ç¡®åŒ¹é…åŠ æƒ
            if token in name:
                score += 10
            if token in keywords:
                score += 5
        
        return min(score, 100)

    def _compute_mcp_score(self, server: dict, tokens: list) -> float:
        """è®¡ç®— MCP æœåŠ¡å™¨çš„åŒ¹é…åˆ†æ•°"""
        score = 0.0
        name = server.get('name', '').lower()
        desc = server.get('description', '').lower()
        keywords = [k.lower() for k in server.get('keywords', [])]
        full_text = f"{name} {desc} {' '.join(keywords)}"
        
        for token in tokens:
            tf = full_text.count(token)
            idf = 1.5 if len(token) > 3 else 1.0
            score += tf * idf
            
            if token in name:
                score += 10
            if token in keywords:
                score += 5
        
        return min(score, 100)

    def handle_mcp_install(self, data: dict):
        """POST /mcp/install - å®‰è£… MCP æœåŠ¡å™¨é…ç½®"""
        server_id = data.get('id', '')
        server_name = data.get('name', server_id)
        command = data.get('command', '')
        args = data.get('args', [])
        env = data.get('env', {})
        
        if not server_name or not command:
            self.send_error_json('Missing required fields: name, command', 400)
            return
        
        # å®‰å…¨æ£€æŸ¥
        if '..' in server_name or '/' in server_name or '\\' in server_name:
            self.send_error_json('Invalid server name', 400)
            return
        
        # è¯»å–ç°æœ‰é…ç½®
        config_path = self.clawd_path / 'mcp-servers.json'
        try:
            if config_path.exists():
                config = json.loads(config_path.read_text(encoding='utf-8'))
            else:
                config = {'servers': {}}
        except Exception as e:
            self.send_error_json(f'Failed to read config: {e}', 500)
            return
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if server_name in config.get('servers', {}):
            self.send_error_json(f'Server already exists: {server_name}', 409)
            return
        
        # æ·»åŠ æ–°æœåŠ¡å™¨é…ç½®
        config['servers'][server_name] = {
            'command': command,
            'args': args,
            'env': env,
            'enabled': False  # é»˜è®¤ç¦ç”¨ï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨å¯ç”¨
        }
        
        # å†™å›é…ç½®æ–‡ä»¶
        try:
            config_path.write_text(json.dumps(config, indent=2, ensure_ascii=False), encoding='utf-8')
        except Exception as e:
            self.send_error_json(f'Failed to write config: {e}', 500)
            return
        
        self.send_json({
            'status': 'ok',
            'serverName': server_name,
            'message': f'MCP server "{server_name}" added (disabled by default). Enable it in mcp-servers.json to use.',
            'configPath': str(config_path)
        })

    # ============================================
    # ğŸ“¦ è¿œç¨‹æŠ€èƒ½å®‰è£…/å¸è½½
    # ============================================

    def handle_skill_install(self, data):
        """POST /skills/install - ä» Git URL å®‰è£…æŠ€èƒ½"""
        source = data.get('source', '')
        name = data.get('name', '')

        if not source:
            self.send_error_json('Missing source parameter', 400)
            return

        if not source.startswith(('http://', 'https://', 'git@')):
            self.send_error_json('Unsupported source format. Use a Git URL (https://... or git@...)', 400)
            return

        try:
            # ä» URL æå–ä»“åº“å
            match = re.search(r'/([^/]+?)(?:\.git)?$', source)
            repo_name = name or (match.group(1) if match else 'downloaded-skill')
            # å®‰å…¨åŒ–åç§°
            repo_name = re.sub(r'[^\w\-.]', '_', repo_name)

            target = self.clawd_path / 'skills' / repo_name
            if target.exists():
                self.send_error_json(f'Skill already exists: {repo_name}. Use /skills/uninstall first.', 409)
                return

            # ç¡®ä¿ skills/ ç›®å½•å­˜åœ¨
            (self.clawd_path / 'skills').mkdir(parents=True, exist_ok=True)

            # Git clone (shallow, é™åˆ¶æ·±åº¦)
            process = subprocess.run(
                ['git', 'clone', '--depth', '1', source, str(target)],
                capture_output=True,
                text=True,
                timeout=120,
            )

            if process.returncode != 0:
                # æ¸…ç†å¤±è´¥çš„ clone
                if target.exists():
                    shutil.rmtree(target, ignore_errors=True)
                stderr = process.stderr[:500] if process.stderr else 'Unknown error'
                raise RuntimeError(f"git clone failed: {stderr}")

            # éªŒè¯: å¿…é¡»æœ‰ SKILL.md æˆ– manifest.json
            has_skill_md = (target / 'SKILL.md').exists() or any(target.rglob('SKILL.md'))
            has_manifest = (target / 'manifest.json').exists()

            if not has_skill_md and not has_manifest:
                shutil.rmtree(target, ignore_errors=True)
                self.send_error_json('Invalid skill: no SKILL.md or manifest.json found', 400)
                return

            # é‡æ–°æ‰«ææ³¨å†Œ
            self.registry.plugin_tools.clear()
            self.registry.instruction_tools.clear()
            self.registry.scan_plugins()

            self.send_json({
                'status': 'ok',
                'name': repo_name,
                'path': str(target),
                'message': f'Skill installed: {repo_name}',
                'toolCount': len(self.registry.list_all()),
            })

        except subprocess.TimeoutExpired:
            if target.exists():
                shutil.rmtree(target, ignore_errors=True)
            self.send_error_json('Git clone timed out (120s limit)', 500)
        except RuntimeError as e:
            self.send_error_json(str(e), 500)
        except Exception as e:
            self.send_error_json(f'Installation failed: {str(e)}', 500)

    def handle_skill_uninstall(self, data):
        """POST /skills/uninstall - å¸è½½æŠ€èƒ½"""
        name = data.get('name', '')

        if not name:
            self.send_error_json('Missing name parameter', 400)
            return

        # å®‰å…¨æ£€æŸ¥: ä¸å…è®¸è·¯å¾„éå†
        if '..' in name or '/' in name or '\\' in name:
            self.send_error_json('Invalid skill name', 400)
            return

        target = self.clawd_path / 'skills' / name

        if not target.exists():
            self.send_error_json(f'Skill not found: {name}', 404)
            return

        if not target.is_dir():
            self.send_error_json(f'Not a directory: {name}', 400)
            return

        try:
            shutil.rmtree(target)

            # é‡æ–°æ‰«æ
            self.registry.plugin_tools.clear()
            self.registry.instruction_tools.clear()
            self.registry.scan_plugins()

            self.send_json({
                'status': 'ok',
                'name': name,
                'message': f'Skill uninstalled: {name}',
                'toolCount': len(self.registry.list_all()),
            })

        except Exception as e:
            self.send_error_json(f'Uninstall failed: {str(e)}', 500)

    def handle_trace_save(self, data):
        """POST /api/traces/save - ä¿å­˜æ‰§è¡Œè¿½è¸ª (P2: æ‰§è¡Œæµè®°å¿†)"""
        if not data:
            self.send_error_json('Missing trace data', 400)
            return

        traces_dir = self.clawd_path / 'memory' / 'exec_traces'
        traces_dir.mkdir(parents=True, exist_ok=True)

        # æŒ‰æœˆåˆ†ç‰‡å­˜å‚¨
        month = datetime.now().strftime('%Y-%m')
        trace_file = traces_dir / f'{month}.jsonl'

        # æ•æ„Ÿæ•°æ®è„±æ•
        trace_json = json.dumps(data, ensure_ascii=False)
        import re
        trace_json = re.sub(
            r'(password|token|secret|api_key|apikey|auth)["\s:]*["\']([^"\']{3,})["\']',
            r'\1": "***"',
            trace_json,
            flags=re.IGNORECASE
        )

        try:
            with open(trace_file, 'a', encoding='utf-8') as f:
                f.write(trace_json + '\n')

            self.send_json({
                'status': 'ok',
                'message': f'Trace saved to {month}.jsonl',
            })
        except Exception as e:
            self.send_error_json(f'Failed to save trace: {e}', 500)

    def handle_trace_search(self, query_params):
        """GET /api/traces/search?query=xxx&limit=5 - æ£€ç´¢æ‰§è¡Œè¿½è¸ª (P2)"""
        query = query_params.get('query', [''])[0]
        limit = min(int(query_params.get('limit', ['5'])[0]), 20)

        if not query:
            self.send_json([])
            return

        traces_dir = self.clawd_path / 'memory' / 'exec_traces'
        if not traces_dir.exists():
            self.send_json([])
            return

        query_lower = query.lower()
        query_words = [w for w in query_lower.split() if len(w) > 1]
        results = []

        # ä»æœ€è¿‘çš„æœˆä»½æ–‡ä»¶å¼€å§‹æœç´¢
        for trace_file in sorted(traces_dir.glob('*.jsonl'), reverse=True)[:6]:
            try:
                for line in reversed(trace_file.read_text(encoding='utf-8').strip().split('\n')):
                    if not line.strip():
                        continue
                    try:
                        trace = json.loads(line)
                        task = trace.get('task', '').lower()
                        tags = [t.lower() for t in trace.get('tags', [])]
                        # å…³é”®è¯åŒ¹é…: task æè¿°æˆ– tags
                        matched = any(w in task for w in query_words) or \
                                  any(w in ' '.join(tags) for w in query_words)
                        if matched:
                            results.append(trace)
                            if len(results) >= limit:
                                break
                    except json.JSONDecodeError:
                        continue
            except Exception:
                continue
            if len(results) >= limit:
                break

        self.send_json(results)
    
    def handle_trace_recent(self, query_params):
        """GET /api/traces/recent?days=3&limit=100 - è·å–æœ€è¿‘Nå¤©çš„æ‰§è¡Œæ—¥å¿— (ä¾› Observer åˆ†æ)"""
        days = min(int(query_params.get('days', ['3'])[0]), 30)
        limit = min(int(query_params.get('limit', ['100'])[0]), 500)
        
        traces_dir = self.clawd_path / 'memory' / 'exec_traces'
        if not traces_dir.exists():
            self.send_json({'traces': [], 'stats': {}})
            return
        
        cutoff_time = datetime.now() - timedelta(days=days)
        cutoff_ts = cutoff_time.timestamp() * 1000  # æ¯«ç§’æ—¶é—´æˆ³
        
        traces = []
        tool_freq = {}  # å·¥å…·ä½¿ç”¨é¢‘ç‡
        nexus_freq = {}  # Nexus ä½¿ç”¨é¢‘ç‡
        total_turns = 0
        total_errors = 0
        
        # ä»æœ€è¿‘çš„æœˆä»½æ–‡ä»¶å¼€å§‹è¯»å–
        for trace_file in sorted(traces_dir.glob('*.jsonl'), reverse=True)[:3]:
            try:
                for line in reversed(trace_file.read_text(encoding='utf-8').strip().split('\n')):
                    if not line.strip():
                        continue
                    try:
                        trace = json.loads(line)
                        ts = trace.get('timestamp', 0)
                        if ts < cutoff_ts:
                            continue  # è¶…å‡ºæ—¶é—´èŒƒå›´
                        
                        traces.append(trace)
                        
                        # ç»Ÿè®¡å·¥å…·é¢‘ç‡
                        for tool in trace.get('tools', []):
                            tool_name = tool.get('name', 'unknown')
                            tool_freq[tool_name] = tool_freq.get(tool_name, 0) + 1
                        
                        # ç»Ÿè®¡ Nexus é¢‘ç‡
                        nexus_id = trace.get('activeNexusId')
                        if nexus_id:
                            nexus_freq[nexus_id] = nexus_freq.get(nexus_id, 0) + 1
                        
                        # ç»Ÿè®¡è½®æ¬¡å’Œé”™è¯¯
                        total_turns += trace.get('turnCount', 0)
                        total_errors += trace.get('errorCount', 0)
                        
                        if len(traces) >= limit:
                            break
                    except json.JSONDecodeError:
                        continue
            except Exception:
                continue
            if len(traces) >= limit:
                break
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        traces.sort(key=lambda t: t.get('timestamp', 0), reverse=True)
        
        self.send_json({
            'traces': traces,
            'stats': {
                'totalExecutions': len(traces),
                'toolFrequency': tool_freq,
                'nexusFrequency': nexus_freq,
                'avgTurnsPerExecution': total_turns / len(traces) if traces else 0,
                'totalErrors': total_errors,
                'timeRangeDays': days,
            }
        })
    
    def handle_memories(self):
        memories = []
        
        memory_md = self.clawd_path / 'MEMORY.md'
        if memory_md.exists():
            try:
                content = memory_md.read_text(encoding='utf-8')
                memories.extend(parse_memory_md(content))
            except:
                pass
        
        memory_dir = self.clawd_path / 'memory'
        if memory_dir.exists() and memory_dir.is_dir():
            for item in memory_dir.iterdir():
                if item.is_file() and item.suffix == '.md':
                    try:
                        content = item.read_text(encoding='utf-8')
                        memories.append({
                            'id': f'file-{item.stem}',
                            'title': item.stem.replace('-', ' ').replace('_', ' ').title(),
                            'content': content[:500],
                            'type': 'long-term',
                            'timestamp': item.stat().st_mtime,
                            'tags': [],
                        })
                    except:
                        pass
        
        self.send_json(memories)
    
    def handle_all(self):
        data = {
            'soul': None,
            'identity': None,
            'skills': [],
            'memories': [],
            'files': list_files(self.clawd_path),
        }
        
        soul_path = self.clawd_path / 'SOUL.md'
        if soul_path.exists():
            try:
                data['soul'] = soul_path.read_text(encoding='utf-8')
            except:
                pass
        
        identity_path = self.clawd_path / 'IDENTITY.md'
        if identity_path.exists():
            try:
                data['identity'] = identity_path.read_text(encoding='utf-8')
            except:
                pass
        
        skills_dir = self.clawd_path / 'skills'
        if skills_dir.exists():
            for item in skills_dir.iterdir():
                if item.is_dir():
                    data['skills'].append({
                        'name': item.name,
                        'location': 'local',
                        'status': 'active',
                        'enabled': True,
                    })
        
        memory_md = self.clawd_path / 'MEMORY.md'
        if memory_md.exists():
            try:
                content = memory_md.read_text(encoding='utf-8')
                data['memories'] = parse_memory_md(content)
            except:
                pass
        
        self.send_json(data)
    
    def handle_task_execute(self, data):
        """å…¼å®¹æ—§çš„ä»»åŠ¡æ‰§è¡Œæ¥å£"""
        prompt = data.get('prompt', '').strip()
        if not prompt:
            self.send_error_json('Missing prompt', 400)
            return
        
        task_id = str(uuid.uuid4())[:8]
        
        thread = threading.Thread(
            target=run_task_in_background,
            args=(task_id, prompt, self.clawd_path),
            daemon=True,
        )
        thread.start()
        
        self.send_json({
            'taskId': task_id,
            'status': 'running',
        })
    
    # ============================================
    # ğŸ¤– å­ä»£ç† API å¤„ç†å™¨ (Quest æ¨¡å¼æ”¯æŒ)
    # ============================================
    
    def handle_subagent_spawn(self, data):
        """å¯åŠ¨å­ä»£ç†"""
        if not self.subagent_manager:
            self.send_error_json('SubagentManager not initialized', 500)
            return
        
        agent_type = data.get('type', 'explore')
        task = data.get('task', '')
        tools = data.get('tools', [])
        context = data.get('context', '')
        
        if not task:
            self.send_error_json('Missing task', 400)
            return
        
        try:
            agent_id = self.subagent_manager.spawn(agent_type, task, tools, context)
            self.send_json({
                'status': 'success',
                'agentId': agent_id,
                'message': f'Spawned {agent_type} agent'
            })
        except Exception as e:
            self.send_error_json(f'Failed to spawn agent: {e}', 500)
    
    def handle_subagent_status(self, agent_id):
        """è·å–å­ä»£ç†çŠ¶æ€"""
        if not self.subagent_manager:
            self.send_error_json('SubagentManager not initialized', 500)
            return
        
        status = self.subagent_manager.get_status(agent_id)
        if status:
            self.send_json({'status': 'success', 'agent': status})
        else:
            self.send_error_json(f'Agent not found: {agent_id}', 404)
    
    def handle_subagent_collect(self, data):
        """æ”¶é›†å¤šä¸ªå­ä»£ç†çš„ç»“æœ"""
        if not self.subagent_manager:
            self.send_error_json('SubagentManager not initialized', 500)
            return
        
        agent_ids = data.get('agentIds', [])
        timeout = data.get('timeout', 60.0)
        
        if not agent_ids:
            # è¿”å›æ‰€æœ‰ä»£ç†çŠ¶æ€
            all_status = self.subagent_manager.get_all_status()
            self.send_json({'status': 'success', 'agents': all_status})
            return
        
        try:
            results = self.subagent_manager.collect_results(agent_ids, timeout)
            self.send_json({'status': 'success', 'results': results})
        except Exception as e:
            self.send_error_json(f'Failed to collect results: {e}', 500)
    
    def handle_task_status(self, task_id, offset=0):
        with self.tasks_lock:
            task = self.tasks.get(task_id)
        
        if not task:
            self.send_error_json(f'Task not found: {task_id}', 404)
            return
        
        log_path = task.get('logPath')
        content = ''
        new_offset = offset
        has_more = False
        file_size = task.get('fileSize', 0)
        
        if log_path:
            content, new_offset, has_more = read_log_chunk(log_path, offset)
            try:
                file_size = Path(log_path).stat().st_size
            except:
                pass
        
        self.send_json({
            'taskId': task_id,
            'status': task['status'],
            'content': content,
            'offset': new_offset,
            'hasMore': has_more,
            'fileSize': file_size,
        })


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def list_files(clawd_path):
    files = []
    try:
        for item in clawd_path.iterdir():
            if item.is_file():
                files.append(item.name)
    except:
        pass
    return sorted(files)


def parse_memory_md(content):
    memories = []
    sections = content.split('## ')
    
    for i, section in enumerate(sections[1:], 1):
        lines = section.strip().split('\n')
        if not lines:
            continue
        
        title = lines[0].strip()
        body = '\n'.join(lines[1:]).strip()
        
        if title:
            memories.append({
                'id': f'memory-{i}',
                'title': title,
                'content': body[:500] if body else title,
                'type': 'long-term',
                'timestamp': None,
                'tags': [],
            })
    
    return memories


def read_log_chunk(log_path, offset=0, max_bytes=51200):
    path = Path(log_path)
    if not path.exists():
        return ('', offset, False)
    
    try:
        file_size = path.stat().st_size
    except:
        return ('', offset, False)
    
    if offset >= file_size:
        return ('', offset, False)
    
    try:
        with open(path, 'rb') as f:
            f.seek(offset)
            raw = f.read(max_bytes)
        
        content = raw.decode('utf-8', errors='replace')
        new_offset = offset + len(raw)
        has_more = new_offset < file_size
        return (content, new_offset, has_more)
    except Exception as e:
        return (f'[æ—¥å¿—è¯»å–é”™è¯¯: {e}]', offset, False)


def run_task_in_background(task_id, prompt, clawd_path):
    logs_dir = clawd_path / 'logs'
    logs_dir.mkdir(exist_ok=True)
    log_file = logs_dir / f"{task_id}.log"
    
    with ClawdDataHandler.tasks_lock:
        ClawdDataHandler.tasks[task_id] = {
            'taskId': task_id,
            'status': 'running',
            'logPath': str(log_file),
            'fileSize': 0,
        }
    
    try:
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"Task: {prompt}\n")
            f.write(f"Started: {datetime.now().isoformat()}\n")
            f.write("-" * 50 + "\n\n")
        
        # å°è¯•è¿è¡Œ clawdbotï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ¨¡æ‹Ÿ
        try:
            with open(log_file, 'ab') as f:
                process = subprocess.Popen(
                    ['clawdbot', 'agent', '--agent', 'main', '--message', prompt],
                    cwd=str(clawd_path),
                    stdout=f,
                    stderr=subprocess.STDOUT,
                )
                
                start_time = time.time()
                timeout = 300
                
                while process.poll() is None:
                    time.sleep(0.5)
                    try:
                        with ClawdDataHandler.tasks_lock:
                            ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
                    except:
                        pass
                    
                    if time.time() - start_time > timeout:
                        process.kill()
                        process.wait()
                        with ClawdDataHandler.tasks_lock:
                            ClawdDataHandler.tasks[task_id]['status'] = 'error'
                            ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
                        with open(log_file, 'a', encoding='utf-8') as ef:
                            ef.write(f'\n\n[é”™è¯¯] ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ ({timeout}s)\n')
                        return
                
                process.wait()
            
            with ClawdDataHandler.tasks_lock:
                ClawdDataHandler.tasks[task_id]['status'] = 'done' if process.returncode == 0 else 'error'
                ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
        
        except FileNotFoundError:
            # clawdbot ä¸å­˜åœ¨ï¼Œä½¿ç”¨ Native æ¨¡å¼æç¤º
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write("\n[DD-OS Native] clawdbot æœªå®‰è£…ã€‚\n")
                f.write("åœ¨ Native æ¨¡å¼ä¸‹ï¼Œè¯·ä½¿ç”¨ /api/tools/execute æ¥å£ç›´æ¥æ‰§è¡Œå·¥å…·ã€‚\n")
                f.write("\nä»»åŠ¡å·²è®°å½•ï¼Œç­‰å¾… AI å¼•æ“å¤„ç†ã€‚\n")
            
            with ClawdDataHandler.tasks_lock:
                ClawdDataHandler.tasks[task_id]['status'] = 'done'
                ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size
    
    except Exception as e:
        with open(log_file, 'a', encoding='utf-8') as ef:
            ef.write(f'\n\n[é”™è¯¯] {str(e)}\n')
        with ClawdDataHandler.tasks_lock:
            ClawdDataHandler.tasks[task_id]['status'] = 'error'
            ClawdDataHandler.tasks[task_id]['fileSize'] = log_file.stat().st_size


def cleanup_old_logs(clawd_path, max_age_hours=24):
    logs_dir = clawd_path / 'logs'
    if not logs_dir.exists():
        return
    
    now = time.time()
    count = 0
    for f in logs_dir.glob('*.log'):
        try:
            age = now - f.stat().st_mtime
            if age > max_age_hours * 3600:
                f.unlink()
                count += 1
        except:
            pass
    
    if count > 0:
        print(f"[Cleanup] Removed {count} old log files")


def cleanup_old_traces(clawd_path, max_months=6):
    """æ¸…ç†è¿‡æœŸçš„æ‰§è¡Œè¿½è¸ªæ–‡ä»¶ (P2: ä¿ç•™æœ€è¿‘Nä¸ªæœˆ)"""
    traces_dir = clawd_path / 'memory' / 'exec_traces'
    if not traces_dir.exists():
        return

    files = sorted(traces_dir.glob('*.jsonl'))
    if len(files) <= max_months:
        return

    old_files = files[:-max_months]
    for f in old_files:
        try:
            f.unlink()
            print(f"[Cleanup] Removed old trace: {f.name}")
        except:
            pass


def cleanup_temp_uploads(clawd_path, max_age_hours=1):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šæ—¶é—´çš„ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶"""
    upload_dir = clawd_path / 'temp' / 'uploads'
    if not upload_dir.exists():
        return
    
    now = time.time()
    count = 0
    for f in upload_dir.iterdir():
        try:
            if f.is_file() and (now - f.stat().st_mtime) > max_age_hours * 3600:
                f.unlink()
                count += 1
        except:
            pass
    
    if count > 0:
        print(f"[Cleanup] Removed {count} old temp upload files")


def main():
    parser = argparse.ArgumentParser(description='DD-OS Native Server')
    parser.add_argument('--port', type=int, default=3001, help='Server port (default: 3001)')
    # æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–é»˜è®¤è·¯å¾„
    default_path = os.getenv('DDOS_DATA_PATH', '~/.ddos')
    parser.add_argument('--path', type=str, default=default_path, help='Data directory path (default: ~/.ddos)')
    parser.add_argument('--host', type=str, default='0.0.0.0', help='Server host (default: 0.0.0.0)')
    args = parser.parse_args()
    
    clawd_path = Path(args.path).expanduser().resolve()
    
    if not clawd_path.exists():
        print(f"Creating data directory: {clawd_path}")
        clawd_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºé»˜è®¤ SOUL.md
        soul_file = clawd_path / 'SOUL.md'
        soul_file.write_text("""# DD-OS Native Soul

You are DD-OS, a local AI operating system running directly on the user's computer.

## Core Principles
- Be helpful and efficient
- Protect user data and privacy
- Execute tasks safely
- Learn from interactions

## Available Tools
- readFile: Read file contents
- writeFile: Write file contents
- listDir: List directory contents
- runCmd: Execute shell commands

## Safety Rules
- Never delete system files
- Ask before destructive operations
- Keep execution logs
""", encoding='utf-8')
        print(f"Created default SOUL.md")
    
    logs_dir = clawd_path / 'logs'
    logs_dir.mkdir(exist_ok=True)
    
    memory_dir = clawd_path / 'memory'
    memory_dir.mkdir(exist_ok=True)
    
    skills_dir = clawd_path / 'skills'
    skills_dir.mkdir(exist_ok=True)
    
    cleanup_old_logs(clawd_path)
    
    # ğŸ”Œ åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨
    registry = ToolRegistry(clawd_path)
    # æ³¨å†Œå†…ç½®å·¥å…·
    builtin_names = [
        'readFile', 'writeFile', 'appendFile', 'listDir', 'runCmd',
        'weather', 'webSearch', 'webFetch', 'saveMemory', 'searchMemory',
        'nexusBindSkill', 'nexusUnbindSkill', 'openInExplorer', 'parseFile',
        'generateSkill',
    ]
    for name in builtin_names:
        registry.register_builtin(name, name)  # handler resolved at dispatch time
    # æ‰«ææ’ä»¶å·¥å…·
    registry.scan_plugins()
    # æ‰«æ MCP æœåŠ¡å™¨
    registry.scan_mcp_servers()

    # æ¸…ç†è¿‡æœŸæ‰§è¡Œè¿½è¸ª (P2: ä¿ç•™æœ€è¿‘6ä¸ªæœˆ)
    cleanup_old_traces(clawd_path)
    cleanup_temp_uploads(clawd_path)

    # é¡¹ç›®ç›®å½• (è„šæœ¬æ‰€åœ¨ç›®å½•)
    project_path = Path(__file__).parent.resolve()
    
    ClawdDataHandler.clawd_path = clawd_path
    ClawdDataHandler.project_path = project_path
    ClawdDataHandler.registry = registry
    ClawdDataHandler.subagent_manager = SubagentManager(registry)
    
    server = ThreadingHTTPServer((args.host, args.port), ClawdDataHandler)
    
    tool_names = [t['name'] for t in registry.list_all()]
    plugin_count = len(registry.plugin_tools)
    mcp_count = len(registry.mcp_tools)
    print(f"""
+==================================================================+
|              DD-OS Native Server v{VERSION}                         |
+==================================================================+
|  Mode:    NATIVE (standalone, no OpenClaw needed)                |
|  Server:  http://{args.host}:{args.port}                                    |
|  Data:    {str(clawd_path)[:50]:<50} |
+------------------------------------------------------------------+
|  Tools:   {len(tool_names)} registered ({len(builtin_names)} builtin + {plugin_count} plugins + {mcp_count} mcp)    |
|  API:     /api/tools/execute (POST)  |  /tools (GET)            |
+==================================================================+
    """)
    
    print(f"Press Ctrl+C to stop\n")
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nShutting down...")
        server.shutdown()


if __name__ == '__main__':
    main()
